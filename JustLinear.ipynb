{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run just the linear regression, as a benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run just the linear regression, against each of the created pre-processed data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's take care of the imports/functions to get running..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_cats.csv\n",
      "data_conts.csv\n",
      "data_new.csv\n",
      "data_orig_only.csv\n",
      "test.csv\n",
      "test.csv.zip\n",
      "test_data_cats.csv\n",
      "test_data_conts.csv\n",
      "test_data_data_new.csv\n",
      "test_data_orig_only.csv\n",
      "train.csv\n",
      "train.csv.zip\n",
      "\n",
      "clusters_cat.npy\n",
      "clusters_cat.npy_01.npy\n",
      "clusters_cat.npy_02.npy\n",
      "clusters_cont.npy\n",
      "clusters_cont.npy_01.npy\n",
      "clusters_cont.npy_02.npy\n",
      "clusters.npy\n",
      "clusters.npy_01.npy\n",
      "clusters.npy_02.npy\n",
      "grid_L2_KNN.pkl\n",
      "grid_L2_Lin.pkl\n",
      "grid_regr0.pkl\n",
      "grid_regr1.pkl\n",
      "grid_regr2.pkl\n",
      "grid_regr3.pkl\n",
      "MAE_tracking.npy\n",
      "oldmodels\n",
      "x_layer2.npy\n",
      "x_layer2.npy_01.npy\n",
      "x_layer2_w_clusters.npy\n",
      "x_layer2_w_clusters.npy_01.npy\n",
      "\n",
      "result_submission_orig_only_linear.csv\n",
      "result_submission_stack_linear.csv\n",
      "result_submission_stack_xgb.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os,sys,time,random,math,time\n",
    "import tarfile, zipfile\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from subprocess import check_output\n",
    "datadir=\"./input/\"\n",
    "cachedir=\"./cache/\"\n",
    "outdir='./output/'\n",
    "\n",
    "print(check_output([\"ls\", datadir]).decode(\"utf8\"))\n",
    "print(check_output([\"ls\", cachedir]).decode(\"utf8\"))\n",
    "print(check_output([\"ls\", outdir]).decode(\"utf8\"))\n",
    "\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(datadir,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    #data = pd.read_csv(filename)\n",
    "    data = ''\n",
    "    print (\"loading: \"+datadir+filename)\n",
    "    try:\n",
    "        if zipfile.is_zipfile(datadir+filename):\n",
    "            z = zipfile.ZipFile(datadir+filename)\n",
    "            filename = z.open(filename[:-4])\n",
    "        else:\n",
    "            filename=datadir+filename\n",
    "        data = pd.read_csv(filename, parse_dates=True)  \n",
    "        print (\"Dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be loaded. Is the dataset missing?\")\n",
    "        print(e)\n",
    "    return data\n",
    "\n",
    "def writeData(data,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    try:\n",
    "        data.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be written.\")\n",
    "        print(e)\n",
    "    verify=[]\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                verify.append(line)\n",
    "        f.closed\n",
    "        return verify[:5]\n",
    "    except IOError:\n",
    "        sys.std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_wrapper(x,y,regr,param,regr_name='BLANK'):\n",
    "    start_time = time.time()\n",
    "    print(\"In:{}\".format(regr))\n",
    "    filename= 'grid_{}.pkl'.format(regr_name)\n",
    "    if os.path.isfile(cachedir+filename):\n",
    "        print filename,\" exists, importing \"\n",
    "        return joblib.load(cachedir+filename) \n",
    "    else:\n",
    "        print(\"{} not present, running a gridsearch\".format(filename))\n",
    "        #search the param_grid for best params based on the f1 score\n",
    "        grid_search = GridSearchCV(regr,\n",
    "                                   param_grid= param,\n",
    "                                   n_jobs= -1,\n",
    "                                   scoring=make_scorer(mean_absolute_error,greater_is_better=False)) \n",
    "        print(\"debug 1\")\n",
    "        grid_search.fit(x,y)\n",
    "        print \"debug2\"\n",
    "        #reach into the grid search and pull out the best parameters, and set those on the clf\n",
    "        params={}\n",
    "        for p in grid_search.best_params_:\n",
    "            params[p]=grid_search.best_params_[p]\n",
    "        regr.set_params(**params)\n",
    "        print(\"run time:{}s\".format(round((time.time()-start_time), 3) ))   \n",
    "        joblib.dump(regr,cachedir+filename) \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepdata(data_name,verbose=False):\n",
    "    ### and now, let's import the data\n",
    "    data = loadData(datadir,'data_'+data_name+'.csv')\n",
    "    if verbose==True:\n",
    "        display(data.info())\n",
    "        display(data.head(2))\n",
    "\n",
    "    test_data= loadData(datadir,'test_data_'+data_name+'.csv') \n",
    "    if verbose==True:\n",
    "        display(test_data.info())\n",
    "        display(test_data.head(2))\n",
    "    # we don't want the ID columns in X\n",
    "    x=data.drop(['id','loss'],1).values\n",
    "    # loss is our label\n",
    "    #y=data['loss'].values\n",
    "    shift=200\n",
    "    y = np.log(data['loss']+shift).ravel()\n",
    "\n",
    "    return x,y,test_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  def predict_for_dataset(data_name):\n",
    "    #for the current data, load and prep     \n",
    "    x,y,test_data=prepdata(data_name)\n",
    "    \n",
    "    #  train/validation split\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split( x,\n",
    "                                                                    y,\n",
    "                                                                   test_size=0.20,\n",
    "                                                                    random_state=42)\n",
    "    display(\"sample train data size:{}\".format(len(y_train)))\n",
    "\n",
    "    #set up our regression\n",
    "    estimator=LinearRegression(n_jobs=-1)\n",
    "    \n",
    "    #train the estimator\n",
    "    start_time = time.time()\n",
    "    estimator.fit(X_train,y_train)\n",
    "    fit_time=time.time()-start_time\n",
    "    \n",
    "    #test on the validation set\n",
    "    start_time = time.time()\n",
    "    curr_predict=np.array(estimator.predict(X_validation)).copy()\n",
    "    predict_time=time.time()-start_time\n",
    "\n",
    "    #track the run info\n",
    "    MAE=np.mean(abs(np.exp(curr_predict) - np.exp(y_validation)))\n",
    "\n",
    "    #show some stats on that last regressions run\n",
    "    print(\"\\nfit time:{}s\".format(round(fit_time, 3) ))\n",
    "    print(\"Mean abs error: {:.2f}\".format(MAE))\n",
    "    print(\"predict time:{}s\".format(round(predict_time, 3) ))\n",
    "\n",
    "\n",
    "    #the Final Prediction on the test data\n",
    "    x_test_data=test_data.drop(['loss','id'],1) .values# didn't have the loss column before, make it go away! don't need ID!\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_data['loss']=np.exp(estimator.predict(x_test_data))-200\n",
    "    final_predict_time=time.time()-start_time\n",
    "    del x_test_data\n",
    "\n",
    "    result=test_data[['id','loss',]]\n",
    "    output_fname='result_submission_'+data_name+'_linear.csv'\n",
    "    print(\"\\nFinal predict time:{}\\nfinal sample\".format(final_predict_time))\n",
    "    display(writeData(result,outdir+output_fname))\n",
    "    return [\"run:{}\".format(data_name),MAE,start_time,predict_time,final_predict_time]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ./input/data_orig_only.csv\n",
      "Dataset has 188318 samples with 132 features each.\n",
      "loading: ./input/test_data_orig_only.csv\n"
     ]
    }
   ],
   "source": [
    "stat_tracking=[]\n",
    "data_name='orig_only'\n",
    "stat_tracking.append(predict_for_dataset(data_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: wrap the above in a function and run for each data set, and plot times, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
