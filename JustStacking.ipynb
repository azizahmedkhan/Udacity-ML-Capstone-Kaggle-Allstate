{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Just a nice stacking ensemble model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "test.csv.zip\n",
      "test_data_all_features.csv\n",
      "test_data_cats.csv\n",
      "test_data_conts.csv\n",
      "test_data_new.csv\n",
      "test_data_orig_only.csv\n",
      "train.csv\n",
      "train.csv.zip\n",
      "train_data_all_features.csv\n",
      "train_data_cats.csv\n",
      "train_data_conts.csv\n",
      "train_data_new.csv\n",
      "train_data_orig_only.csv\n",
      "\n",
      "clusters_cat.npy\n",
      "clusters_cat.npy_01.npy\n",
      "clusters_cat.npy_02.npy\n",
      "clusters_cont.npy\n",
      "clusters_cont.npy_01.npy\n",
      "clusters_cont.npy_02.npy\n",
      "clusters.npy\n",
      "clusters.npy_01.npy\n",
      "clusters.npy_02.npy\n",
      "grid_L2_KNN.pkl\n",
      "grid_L2_Lin.pkl\n",
      "grid_regr0.pkl\n",
      "grid_regr1.pkl\n",
      "grid_regr2.pkl\n",
      "grid_regr3.pkl\n",
      "MAE_tracking.npy\n",
      "oldmodels\n",
      "stat_tracking-Linear.npy\n",
      "x_layer2.npy\n",
      "x_layer2.npy_01.npy\n",
      "x_layer2_w_clusters.npy\n",
      "x_layer2_w_clusters.npy_01.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os,sys,time,random,math,time\n",
    "import tarfile, zipfile\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor,RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import decomposition, datasets, ensemble\n",
    "from sklearn.cluster import KMeans,MeanShift\n",
    "\n",
    "from sklearn.base import clone as skclone\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import make_scorer,precision_score, recall_score, f1_score, average_precision_score, accuracy_score, mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import itertools\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Activation\n",
    "#from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "use_xgb=True #disable for speed\n",
    "\n",
    "from subprocess import check_output\n",
    "datadir=\"./input/\"\n",
    "cachedir=\"./cache/\"\n",
    "print(check_output([\"ls\", datadir]).decode(\"utf8\"))\n",
    "print(check_output([\"ls\", cachedir]).decode(\"utf8\"))\n",
    "\n",
    "\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(datadir,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    #data = pd.read_csv(filename)\n",
    "    data = ''\n",
    "    print (\"loading: \"+datadir+filename)\n",
    "    try:\n",
    "        if zipfile.is_zipfile(datadir+filename):\n",
    "            z = zipfile.ZipFile(datadir+filename)\n",
    "            filename = z.open(filename[:-4])\n",
    "        else:\n",
    "            filename=datadir+filename\n",
    "        data = pd.read_csv(filename, parse_dates=True)  \n",
    "        print (\"Dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be loaded. Is the dataset missing?\")\n",
    "        print(e)\n",
    "    return data\n",
    "\n",
    "def writeData(data,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    try:\n",
    "        data.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be written.\")\n",
    "        print(e)\n",
    "    verify=[]\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                verify.append(line)\n",
    "        f.closed\n",
    "        return verify[:5]\n",
    "    except IOError:\n",
    "        sys.std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepdata(data_name,verbose=False):\n",
    "    ### and now, let's import the data\n",
    "    data = loadData(datadir,'train_data_'+data_name+'.csv')\n",
    "    if verbose==True:\n",
    "        display(data.info())\n",
    "        display(data.head(2))\n",
    "\n",
    "    test_data= loadData(datadir,'test_data_'+data_name+'.csv') \n",
    "    if verbose==True:\n",
    "        display(test_data.info())\n",
    "        display(test_data.head(2))\n",
    "    # we don't want the ID columns in X\n",
    "    x=data.drop(['id','loss'],1).values\n",
    "    # loss is our label\n",
    "    #y=data['loss'].values\n",
    "    y = np.log(data['loss']+shift).ravel()\n",
    "\n",
    "    return x,y,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def LabelEncoder(data):\n",
    "    # lifted in parts from:\n",
    "    #https://www.kaggle.com/mmueller/allstate-claims-severity/yet-another-xgb-starter/code\n",
    "    features = data.columns\n",
    "    cats = [feat for feat in features if 'cat' in feat]\n",
    "    for feat in cats:\n",
    "        data[feat] = pd.factorize(data[feat], sort=True)[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeansPlusmeanshift(data):\n",
    "    start_time = time.time()\n",
    "    startingClusterSize=int(len(data)*.075)\n",
    "    print \"kmeans.... for {} clusters\".format(startingClusterSize)\n",
    "    k_means =KMeans(n_clusters=startingClusterSize,n_jobs=10)\n",
    "    k_means.fit(data.sample(frac=0.35).values)\n",
    "    clusters=k_means.cluster_centers_\n",
    "    print(\"kmeans round 1 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    print clusters[:15]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #use the cluster centers of the guessed clusters to get an estimate of actual numbers of clusters. doing this for speed increase!\n",
    "    print \"\\nmeanshift...\"\n",
    "    meanshift=MeanShift(n_jobs=10)\n",
    "    meanshift.fit(clusters)\n",
    "    newcenters=meanshift.cluster_centers_\n",
    "    print(\"meanshift time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    print newcenters[:15], \"\\nnum of clusters from meanshift:\",len(newcenters)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # use the new clusters number to predict each locations cluster\n",
    "    print \"\\nredo kmeans with new cluster number from meanshift +1 to account for sampling...\"\n",
    "    k_means =KMeans(n_clusters=len(newcenters)+1,n_jobs=10)\n",
    "    final_clusters=k_means.fit_predict(data.values)\n",
    "    print(\"kmeans round 2 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeansPlusmeanshift_quick(data):  # used the one above to get the # of clusters, using this for speed\n",
    "    start_time = time.time()\n",
    "    # use the new clusters number to predict each locations cluster\n",
    "    print \"\\nredo kmeans with new cluster number from meanshift +1 to account for sampling...\"\n",
    "    k_means =KMeans(n_clusters=80,n_jobs=12)\n",
    "    final_clusters=k_means.fit_predict(data.values)\n",
    "    print(\"kmeans round 2 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_wrapper(x,y,regr,param,regr_name='BLANK'):\n",
    "    start_time = time.time()\n",
    "    print(\"In:{}\".format(regr))\n",
    "    filename= 'grid_{}.pkl'.format(regr_name)\n",
    "    if os.path.isfile(cachedir+filename):\n",
    "        print filename,\" exists, importing \"\n",
    "        return joblib.load(cachedir+filename) \n",
    "    else:\n",
    "        print(\"{} not present, running a gridsearch\".format(filename))\n",
    "        #search the param_grid for best params based on the f1 score\n",
    "        grid_search = GridSearchCV(regr,\n",
    "                                   param_grid= param,\n",
    "                                   n_jobs= -1,\n",
    "                                   scoring=make_scorer(mean_absolute_error,greater_is_better=False)) \n",
    "        print(\"debug 1\")\n",
    "        grid_search.fit(x,y)\n",
    "        print \"debug2\"\n",
    "        #reach into the grid search and pull out the best parameters, and set those on the clf\n",
    "        params={}\n",
    "        for p in grid_search.best_params_:\n",
    "            params[p]=grid_search.best_params_[p]\n",
    "        regr.set_params(**params)\n",
    "        print(\"run time:{}s\".format(round((time.time()-start_time), 3) ))   \n",
    "        joblib.dump(regr,cachedir+filename) \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pre Proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ./input/train_data_all_features.csv\n",
      "Dataset has 188318 samples with 135 features each.\n",
      "loading: ./input/test_data_all_features.csv\n",
      "Dataset has 125546 samples with 135 features each.\n"
     ]
    }
   ],
   "source": [
    "shift=200\n",
    "\n",
    "data_name='all_features'\n",
    "x,y,test_data=prepdata(data_name)\n",
    "x_test_data=test_data.drop(['loss','id'],1).values# didn't have the loss column before, make it go away! don't need ID!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick our sklearn regressors, and do some param optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      " Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)]\n",
      "[ {'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [3, 5, 7, 10, 25, 50, 200, 500]}\n",
      " {'alpha': [0.05, 0.5, 1, 2, 4, 40, 140, 400]}\n",
      " {'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [2, 5, 7, 10, 25, 50, 200, 500]}]\n",
      "('number of scikitlearn regressors to use:', 3)\n"
     ]
    }
   ],
   "source": [
    "regressor_w_grid=[] # a list of regressions to use\n",
    "#regrList.append([LinearRegression()])\n",
    "regressor_w_grid.append([ExtraTreesRegressor(n_jobs = -1),\n",
    "                         dict(n_estimators=[3,5,7,10,25,50,200,500],\n",
    "                         max_features=['auto','sqrt','log2'])])\n",
    "regressor_w_grid.append([Ridge(),\n",
    "                         dict(alpha=[.05,.5,1,2,4,40,140,400])])\n",
    "regressor_w_grid.append([RandomForestRegressor(#criterion = 'mae',\n",
    "                                      n_jobs =-1, \n",
    "                                      random_state=42),\n",
    "                        dict(n_estimators=[2,5,7,10,25,50,200,500],\n",
    "                             max_features=['auto','sqrt','log2'])])\n",
    "#regressor_w_grid.append([KNeighborsRegressor(n_jobs = -1),\n",
    "                       # dict(n_neighbors=[2,5,7,15],\n",
    "                             #leaf_size =[3,10,15,25,30,50,100])])\n",
    "#regrList.append([SVR(), dict()]) # oh my so slow! and bad initial scores\n",
    "\n",
    "\n",
    "\n",
    "regrList=np.array(regressor_w_grid).T[0]\n",
    "paramater_grid=np.array(regressor_w_grid).T[1]\n",
    "print regrList\n",
    "print paramater_grid\n",
    "\n",
    "print(\"number of scikitlearn regressors to use:\",len(regrList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample train data size:150654'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  train/validation split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split( x,\n",
    "                                                                y,\n",
    "                                                               test_size=0.20,\n",
    "                                                                random_state=42)\n",
    "display(\"sample train data size:{}\".format(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "grid_regr0.pkl  exists, importing \n",
      "In:Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "grid_regr1.pkl  exists, importing \n",
      "In:RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "grid_regr2.pkl  exists, importing \n",
      "Full GridSearch run time:0.003s\n"
     ]
    }
   ],
   "source": [
    "start_time0 = time.time()\n",
    "for i in range(len(regrList)):\n",
    "    regrList[i]=grid_search_wrapper(X_train,y_train,regrList[i],paramater_grid[i],regr_name=\"regr{}\".format(i))\n",
    "    \n",
    "print(\"Full GridSearch run time:{}s\".format(round((time.time()-start_time0), 3) ))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:7.22672+0.00177631\ttest-mae:7.22672+0.00536231\n",
      "[100]\ttrain-mae:2.64648+0.000645226\ttest-mae:2.64657+0.00398503\n",
      "[200]\ttrain-mae:0.981322+0.000437563\ttest-mae:0.982543+0.00375753\n",
      "[300]\ttrain-mae:0.481692+0.000621212\ttest-mae:0.491434+0.00279426\n",
      "[400]\ttrain-mae:0.380619+0.000707563\ttest-mae:0.399574+0.00192014\n",
      "[500]\ttrain-mae:0.357262+0.000700708\ttest-mae:0.382938+0.00164532\n",
      "[600]\ttrain-mae:0.347403+0.000588488\ttest-mae:0.378616+0.00164711\n",
      "[700]\ttrain-mae:0.340663+0.000678476\ttest-mae:0.376688+0.00166054\n",
      "[800]\ttrain-mae:0.335234+0.000764873\ttest-mae:0.375584+0.00167685\n",
      "[900]\ttrain-mae:0.330477+0.000768185\ttest-mae:0.374767+0.00169156\n",
      "[1000]\ttrain-mae:0.326514+0.000812336\ttest-mae:0.374215+0.00172061\n",
      "[1100]\ttrain-mae:0.322813+0.000753445\ttest-mae:0.373784+0.00169393\n",
      "[1200]\ttrain-mae:0.319576+0.000650692\ttest-mae:0.373445+0.00171658\n",
      "[1300]\ttrain-mae:0.316523+0.00038135\ttest-mae:0.373181+0.00173508\n",
      "[1400]\ttrain-mae:0.313847+0.000220668\ttest-mae:0.372989+0.00175072\n",
      "[1500]\ttrain-mae:0.311318+0.000199525\ttest-mae:0.372823+0.00177604\n",
      "[1600]\ttrain-mae:0.308868+0.000166682\ttest-mae:0.372682+0.00176994\n",
      "[1700]\ttrain-mae:0.306419+0.000184337\ttest-mae:0.372563+0.00177345\n",
      "[1800]\ttrain-mae:0.304254+0.000147647\ttest-mae:0.372489+0.00175401\n",
      "[1900]\ttrain-mae:0.302198+0.000212445\ttest-mae:0.372431+0.00174293\n",
      "[2000]\ttrain-mae:0.300258+0.0002254\ttest-mae:0.372382+0.00172094\n",
      "CV time:790.786s\n",
      "CV-Mean: 0.37238175+0.00172093933289\n"
     ]
    }
   ],
   "source": [
    "# XGB!\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "#my first tries:\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 6,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'mae',\n",
    "}\n",
    "#params from:\n",
    "#https://www.kaggle.com/mnabaee/allstate-claims-severity/labelencoding-and-xgb-cv/discussion\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.3085,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.5,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 10,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 4.2922,\n",
    "    'eval_metric': 'mae',\n",
    "    'eta':0.001,\n",
    "    'gamma': 0.5290,\n",
    "    'subsample':0.9930,\n",
    "    'max_delta_step':0,\n",
    "    'booster':'gbtree',\n",
    "    'nrounds': 1001\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=2001, nfold=4, seed=42, stratified=False,\n",
    "             early_stopping_rounds=50, verbose_eval=100, show_stdv=True, maximize=False)\n",
    "print(\"CV time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "print('CV-Mean: {0}+{1}'.format(cv_mean, cv_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X_train, X_validation, y_train, y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Layer 1, train and predict for layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into k-folds(divisions). train the regressors on each combination of k-1 folds, and then predict on the held-out fold. Preserve the prediction of each regressor for the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train data: 188318\n",
      "folds at: [(0, 37663), (37663, 75326), (75326, 112989), (112989, 150652), (150652, 188318)]\n",
      "fold size: 37663\n",
      "train size: 150652\n",
      "188318\n"
     ]
    }
   ],
   "source": [
    "#prepare the fold divisions\n",
    "\n",
    "data_size=x.shape[0]\n",
    "print \"size of train data:\",data_size\n",
    "folds=[]\n",
    "num_folds=5\n",
    "fold_start=0\n",
    "for k in range(num_folds-1):\n",
    "    fold_end=((data_size/num_folds)*(k+1))\n",
    "    folds.append((fold_start,fold_end))\n",
    "    fold_start=fold_end\n",
    "folds.append((fold_start,data_size))\n",
    "print \"folds at:\",folds\n",
    "print \"fold size:\", (data_size/num_folds)\n",
    "print \"train size:\",(data_size/num_folds)*(num_folds-1)\n",
    "\n",
    "count=0\n",
    "for i in folds:\n",
    "    count+=i[1]-i[0]\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Fold:0 to 37663 of: 188318\n",
      "\n",
      "---folding! len test 37663, len train 150655\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "fit time:77.694s\n",
      "Mean abs error: 1212.15\n",
      "-predict time:4.394s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:4.209s\n",
      "Mean abs error: 1278.46\n",
      "-predict time:0.016s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:30: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit time:69.406s\n",
      "Mean abs error: 1203.76\n",
      "-predict time:3.772s\n",
      "XGB Mean abs error: 1138.36\n",
      "-XGB predict time:2.417s\n",
      "--layer2 length: 37663\n",
      "--layer2 shape: (37663, 4)\n",
      "---Fold run time:416.151s\n",
      "---Fold:37663 to 75326 of: 188318\n",
      "\n",
      "---folding! len test 37663, len train 150655\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "fit time:79.219s\n",
      "Mean abs error: 1210.12\n",
      "-predict time:4.156s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:4.031s\n",
      "Mean abs error: 1273.58\n",
      "-predict time:0.013s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "fit time:70.128s\n",
      "Mean abs error: 1204.21\n",
      "-predict time:3.877s\n",
      "XGB Mean abs error: 1133.70\n",
      "-XGB predict time:2.444s\n",
      "--layer2 length: 75326\n",
      "--layer2 shape: (75326, 4)\n",
      "---Fold run time:417.945s\n",
      "---Fold:75326 to 112989 of: 188318\n",
      "\n",
      "---folding! len test 37663, len train 150655\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:58: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit time:80.256s\n",
      "Mean abs error: 1225.63\n",
      "-predict time:4.501s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:4.124s\n",
      "Mean abs error: 1292.36\n",
      "-predict time:0.014s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "fit time:71.116s\n",
      "Mean abs error: 1215.81\n",
      "-predict time:3.787s\n",
      "XGB Mean abs error: 1149.70\n",
      "-XGB predict time:2.53s\n",
      "--layer2 length: 112989\n",
      "--layer2 shape: (112989, 4)\n",
      "---Fold run time:421.219s\n",
      "---Fold:112989 to 150652 of: 188318\n",
      "\n",
      "---folding! len test 37663, len train 150655\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "fit time:80.495s\n",
      "Mean abs error: 1222.34\n",
      "-predict time:4.285s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:3.932s\n",
      "Mean abs error: 1296.75\n",
      "-predict time:0.013s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "fit time:72.175s\n",
      "Mean abs error: 1212.29\n",
      "-predict time:4.078s\n",
      "XGB Mean abs error: 1142.27\n",
      "-XGB predict time:2.584s\n",
      "--layer2 length: 150652\n",
      "--layer2 shape: (150652, 4)\n",
      "---Fold run time:424.711s\n",
      "---Fold:150652 to 188318 of: 188318\n",
      "\n",
      "---folding! len test 37666, len train 150652\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "fit time:81.212s\n",
      "Mean abs error: 1203.62\n",
      "-predict time:4.353s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:4.005s\n",
      "Mean abs error: 1270.93\n",
      "-predict time:0.016s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "fit time:71.598s\n",
      "Mean abs error: 1195.09\n",
      "-predict time:3.766s\n",
      "XGB Mean abs error: 1128.54\n",
      "-XGB predict time:2.589s\n",
      "--layer2 length: 188318\n",
      "--layer2 shape: (188318, 4)\n",
      "---Fold run time:423.739s\n",
      "----Full run time:2103.767s\n"
     ]
    }
   ],
   "source": [
    "x_layer2=[]\n",
    "start_time0 = time.time()\n",
    "MAE_tracking=[]\n",
    "\n",
    "if os.path.isfile(cachedir+'x_layer2.npy'):\n",
    "    print 'x_layer2.npy',\" exists, importing \"\n",
    "    #reuse the run\n",
    "    x_layer2=joblib.load(cachedir+'x_layer2.npy') \n",
    "    MAE_tracking=joblib.load(cachedir+'MAE_tracking.npy')\n",
    "else:\n",
    "    for fold_start,fold_end in folds:\n",
    "        print(\"---Fold:{} to {} of: {}\".format(fold_start,fold_end,data_size))\n",
    "        start_time1 = time.time()\n",
    "        fold_result=[]\n",
    "\n",
    "        X_test = x[fold_start:fold_end].copy()\n",
    "        y_test = y[fold_start:fold_end].copy()\n",
    "        X_train=np.concatenate((x[:fold_start], x[fold_end:]), axis=0)\n",
    "        y_train=np.concatenate((y[:fold_start], y[fold_end:]), axis=0)\n",
    "        print \"\\n---folding! len test {}, len train {}\".format(len(X_test),len(X_train))\n",
    "\n",
    "        for i in range(len(regrList)): # for each of the regressions we use, fit/predict the data\n",
    "            print(regrList[i])\n",
    "            start_time = time.time()\n",
    "            estimator=skclone(regrList[i], safe=True)\n",
    "            estimator.fit(X_train,y_train)\n",
    "            print(\"\\nfit time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "            start_time = time.time()\n",
    "            curr_predict=np.array(estimator.predict(X_test)).copy()\n",
    "            if fold_result == []:\n",
    "                fold_result = curr_predict\n",
    "            else:\n",
    "                fold_result = np.column_stack((fold_result,curr_predict))  \n",
    "            #show some stats on that last regressions run\n",
    "            #MAE=np.mean(abs(curr_predict - y_test))\n",
    "            MAE=np.mean(abs(np.exp(curr_predict) - np.exp(y_test)))\n",
    "            MAE_tracking.append([\"run:{}-{}:{}\".format(fold_start,fold_end,i),MAE])\n",
    "            print(\"Mean abs error: {:.2f}\".format(MAE))\n",
    "            print(\"-predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "            #print(\"Score: {:.2f}\".format(estimator.score(X_test, y_test))) #delays the run...\n",
    "\n",
    "        #XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
    "        if use_xgb == True:\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "            dtest = xgb.DMatrix(X_test)\n",
    "            #gbdt=xgbfit(X_train,y_train)\n",
    "            gbdt=xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "            # now do a prediction and spit out a score(MAE) that means something\n",
    "            start_time = time.time()\n",
    "            curr_predict=gbdt.predict(dtest)\n",
    "            fold_result = np.column_stack((fold_result,curr_predict))   \n",
    "            #MAE=np.mean(abs(curr_predict - y_test))\n",
    "            MAE=np.mean(abs(np.exp(curr_predict) - np.exp(y_test)))\n",
    "            MAE_tracking.append([\"run:{}-{}:{}\".format(fold_start,fold_end,'XGB'),MAE])\n",
    "            print(\"XGB Mean abs error: {:.2f}\".format(MAE))\n",
    "            print(\"-XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "        if x_layer2 == []:\n",
    "            x_layer2=fold_result\n",
    "        else:\n",
    "            x_layer2=np.append(x_layer2,fold_result,axis=0)\n",
    "\n",
    "        print \"--layer2 length:\",len(x_layer2)\n",
    "        print \"--layer2 shape:\",np.shape(x_layer2)\n",
    "        print(\"---Fold run time:{}s\".format(round((time.time()-start_time1), 3) ))   \n",
    "    print(\"----Full run time:{}s\".format(round((time.time()-start_time0), 3) ))   \n",
    "    #preserve the run\n",
    "    joblib.dump(x_layer2,cachedir+'x_layer2.npy') \n",
    "    joblib.dump(MAE_tracking,cachedir+'MAE_tracking.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgd Mean abs error: 1179.07\n",
      "length of new row: 5\n"
     ]
    }
   ],
   "source": [
    "# add an avged column of all the runs\n",
    "\n",
    "avg_column=np.mean(x_layer2, axis=1)\n",
    "\n",
    "#MAE=np.mean(abs(avg_column - y))\n",
    "MAE=np.mean(abs(np.exp(avg_column) - np.exp(y)))\n",
    "print(\"avgd Mean abs error: {:.2f}\".format(MAE))\n",
    "x_layer2=np.column_stack((x_layer2,avg_column))\n",
    "print(\"length of new row: {}\".format(len(x_layer2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test-first 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.72564088,  7.33350105,  7.77098668,  7.69497013,  7.63127468],\n",
       "       [ 7.69969656,  7.65916132,  7.64628168,  7.56129837,  7.64160948],\n",
       "       [ 8.35786941,  8.50399124,  8.35953566,  8.39824104,  8.40490934]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of row: 5\n"
     ]
    }
   ],
   "source": [
    "display(\"test-first 3\",x_layer2[:3])\n",
    "print(\"length of row: {}\".format(len(x_layer2[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put each in a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "redo kmeans with new cluster number from meanshift to account for sampling...\n",
      "kmeans round 2 time:45.394s\n",
      "length of row: 5\n",
      "length of row: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./cache/x_layer2_w_clusters.npy', './cache/x_layer2_w_clusters.npy_01.npy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "# use the new clusters number to predict each locations cluster\n",
    "print \"\\nredo kmeans with new cluster number from meanshift to account for sampling...\"\n",
    "k_means =KMeans(n_clusters=80,n_jobs=12)\n",
    "final_clusters=k_means.fit_predict(x_layer2)\n",
    "print(\"kmeans round 2 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "print(\"length of row: {}\".format(len(x_layer2[0])))\n",
    "      \n",
    "x_layer2=np.column_stack((x_layer2,final_clusters))\n",
    "print(\"length of row: {}\".format(len(x_layer2[0])))\n",
    "joblib.dump(x_layer2,cachedir+'x_layer2_w_clusters.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_layer2=joblib.load(cachedir+'x_layer2_w_clusters.npy') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "grid_L2_Lin.pkl  exists, importing \n",
      "In:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "          weights='uniform')\n",
      "grid_L2_KNN.pkl  exists, importing \n",
      "Full GridSearch run time:0.05s\n"
     ]
    }
   ],
   "source": [
    "# grid search on layer 2\n",
    "\n",
    "        \n",
    "start_time0 = time.time()\n",
    "\n",
    "paramater_grid_Lin=dict(normalize = [True,False])\n",
    "layer2_Lin_regr=grid_search_wrapper(x_layer2,y,LinearRegression(),paramater_grid_Lin,regr_name='L2_Lin')   \n",
    "\n",
    "paramater_grid_KNN=dict(n_neighbors=[2,5,7,15,30],\n",
    "                    leaf_size =[3,10,15,25,30,50,100])\n",
    "layer2_KNN_regr=grid_search_wrapper(x_layer2,y,KNeighborsRegressor(n_jobs = -1),paramater_grid_KNN,regr_name='L2_KNN')   \n",
    "    \n",
    "print(\"Full GridSearch run time:{}s\".format(round((time.time()-start_time0), 3) ))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:7.22685+0.0019794\ttest-mae:7.22685+0.00597367\n",
      "[100]\ttrain-mae:2.64566+0.00071125\ttest-mae:2.64563+0.00460733\n",
      "[200]\ttrain-mae:0.979774+0.000350709\ttest-mae:0.979845+0.00400455\n",
      "[300]\ttrain-mae:0.478991+0.000504777\ttest-mae:0.480557+0.00251428\n",
      "[400]\ttrain-mae:0.387274+0.000477961\ttest-mae:0.390574+0.00116737\n",
      "[500]\ttrain-mae:0.373197+0.000445189\ttest-mae:0.377459+0.000634498\n",
      "[600]\ttrain-mae:0.370516+0.000390568\ttest-mae:0.375463+0.000484951\n",
      "[700]\ttrain-mae:0.369502+0.000349364\ttest-mae:0.375044+0.000446149\n",
      "[800]\ttrain-mae:0.368708+0.000327205\ttest-mae:0.374836+0.000428095\n",
      "[900]\ttrain-mae:0.36803+0.000348059\ttest-mae:0.374731+0.000450785\n",
      "[1000]\ttrain-mae:0.367395+0.000344808\ttest-mae:0.374663+0.000430406\n",
      "[1100]\ttrain-mae:0.366871+0.000346567\ttest-mae:0.37464+0.000429563\n",
      "[1200]\ttrain-mae:0.366356+0.000297069\ttest-mae:0.374615+0.000424738\n",
      "[1300]\ttrain-mae:0.365885+0.000301724\ttest-mae:0.374606+0.000421304\n",
      "CV time:237.837s\n",
      "CV-Mean: 0.37459925+0.000427096227448\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_layer2, label=y)\n",
    "\n",
    "start_time = time.time()\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=2001, nfold=4, seed=42, stratified=False,\n",
    "             early_stopping_rounds=50, verbose_eval=100, show_stdv=True, maximize=False)\n",
    "print(\"CV time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "print('CV-Mean: {0}+{1}'.format(cv_mean, cv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=3, metric='minkowski',\n",
       "          metric_params=None, n_jobs=-1, n_neighbors=30, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(layer2_Lin_regr)\n",
    "display(layer2_KNN_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0 to 37663 of: 188318\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "LinearRegression Mean abs error: 1136.55\n",
      "Score: 0.58\n",
      "KNeighborsRegressor Mean abs error: 1156.20\n",
      "Score: 0.57\n",
      "XGB Mean abs error: 1153.00\n",
      "XGB predict time:1.514s\n",
      "AVG Mean abs error: 1142.57\n",
      "Fold:37663 to 75326 of: 188318\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "LinearRegression Mean abs error: 1131.52\n",
      "Score: 0.58\n",
      "KNeighborsRegressor Mean abs error: 1152.98\n",
      "Score: 0.56\n",
      "XGB Mean abs error: 1149.10\n",
      "XGB predict time:1.268s\n",
      "AVG Mean abs error: 1138.45\n",
      "Fold:75326 to 112989 of: 188318\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "LinearRegression Mean abs error: 1148.08\n",
      "Score: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:67: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor Mean abs error: 1166.89\n",
      "Score: 0.56\n",
      "XGB Mean abs error: 1161.46\n",
      "XGB predict time:1.506s\n",
      "AVG Mean abs error: 1152.21\n",
      "Fold:112989 to 150652 of: 188318\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "LinearRegression Mean abs error: 1140.31\n",
      "Score: 0.57\n",
      "KNeighborsRegressor Mean abs error: 1162.15\n",
      "Score: 0.56\n",
      "XGB Mean abs error: 1157.34\n",
      "XGB predict time:1.306s\n",
      "AVG Mean abs error: 1147.55\n",
      "Fold:150652 to 188318 of: 188318\n",
      "\n",
      "folding! len test 37666, len train 150652\n",
      "LinearRegression Mean abs error: 1126.04\n",
      "Score: 0.58\n",
      "KNeighborsRegressor Mean abs error: 1148.55\n",
      "Score: 0.56\n",
      "XGB Mean abs error: 1141.99\n",
      "XGB predict time:1.509s\n",
      "AVG Mean abs error: 1132.62\n"
     ]
    }
   ],
   "source": [
    "x_layer3 = []\n",
    "\n",
    "for fold_start,fold_end in folds:\n",
    "    print(\"Fold:{} to {} of: {}\".format(fold_start,fold_end,data_size))\n",
    "    start_time1 = time.time()\n",
    "    fold_result=[]\n",
    "    \n",
    "    X_layer2_validation = x_layer2[fold_start:fold_end].copy()\n",
    "    y_layer2_validation = y[fold_start:fold_end].copy()\n",
    "    X_layer2_train=np.concatenate((x_layer2[:fold_start], x_layer2[fold_end:]), axis=0)\n",
    "    y_layer2_train=np.concatenate((y[:fold_start], y[fold_end:]), axis=0)\n",
    "    print \"\\nfolding! len test {}, len train {}\".format(len(X_layer2_validation),len(X_layer2_train))\n",
    "    \n",
    "\n",
    "    layer2_Lin_regr.fit(X_layer2_train,y_layer2_train)\n",
    "    layer2_predict_linear=layer2_Lin_regr.predict(X_layer2_validation)\n",
    "    #show some stats on that last regressions run    \n",
    "    #MAE=np.mean(abs(layer2_predict_linear - y_layer2_validation))\n",
    "    MAE=np.mean(abs(np.exp(layer2_predict_linear) - np.exp(y_layer2_validation)))\n",
    "    MAE_tracking.append([\"run:{}\".format('linearLayer2'),MAE])\n",
    "    print(\"LinearRegression Mean abs error: {:.2f}\".format(MAE))\n",
    "    print(\"Score: {:.2f}\".format(layer2_Lin_regr.score(X_layer2_validation, y_layer2_validation)))\n",
    "    fold_result = layer2_predict_linear\n",
    "    #with LinearReg: Mean abs error: 1172.67\n",
    "\n",
    "    #KNeighborsRegressor\n",
    "    layer2_KNN_regr.fit(X_layer2_train,y_layer2_train)\n",
    "    layer2_predict_KNeighbors=layer2_KNN_regr.predict(X_layer2_validation)\n",
    "    #show some stats on that last regressions run    \n",
    "    #MAE=np.mean(abs(layer2_predict_KNeighbors - y_layer2_validation))\n",
    "    MAE=np.mean(abs(np.exp(layer2_predict_KNeighbors) - np.exp(y_layer2_validation)))\n",
    "    MAE_tracking.append([\"run:{}\".format('KNNLayer2'),MAE])\n",
    "    print(\"KNeighborsRegressor Mean abs error: {:.2f}\".format(MAE))\n",
    "    print(\"Score: {:.2f}\".format(layer2_KNN_regr.score(X_layer2_validation, y_layer2_validation)))\n",
    "    fold_result = np.column_stack((fold_result,layer2_predict_KNeighbors))  \n",
    "\n",
    "    #Mean abs error: 1291.64\n",
    "\n",
    "    # The XGB version of layer 2\n",
    "    dtrain = xgb.DMatrix(X_layer2_train, label=y_layer2_train)\n",
    "    dtest = xgb.DMatrix(X_layer2_validation)\n",
    "    layer2_gbdt=xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "    \n",
    "    # now do a prediction and spit out a score(MAE) that means something\n",
    "    start_time = time.time()\n",
    "    layer2_gbdt_predict=layer2_gbdt.predict(dtest)\n",
    "    #MAE=np.mean(abs(layer2_gbdt_predict- y_layer2_validation))\n",
    "    MAE=np.mean(abs(np.exp(layer2_gbdt_predict) - np.exp(y_layer2_validation)))\n",
    "    MAE_tracking.append([\"run:{}\".format('XGBLayer2'),MAE])\n",
    "    print(\"XGB Mean abs error: {:.2f}\".format(MAE))\n",
    "    print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "    fold_result = np.column_stack((fold_result,layer2_gbdt_predict))  \n",
    "    \n",
    "    #XGB Mean abs error: 1154.25\n",
    "    \n",
    "    # ? average those weighted to XGB\n",
    "    layer2_avg_predict=(layer2_predict_linear+layer2_predict_KNeighbors+layer2_gbdt_predict+layer2_gbdt_predict)/4\n",
    "\n",
    "    #MAE=np.mean(abs(layer2_avg_predict- y_layer2_validation))\n",
    "    MAE=np.mean(abs(np.exp(layer2_avg_predict) - np.exp(y_layer2_validation)))\n",
    "\n",
    "    print(\"AVG Mean abs error: {:.2f}\".format(MAE))\n",
    "    fold_result = np.column_stack((fold_result,layer2_avg_predict))  \n",
    "\n",
    "    #AVG Mean abs error: 1163.71\n",
    "    \n",
    "    if x_layer3 == []:\n",
    "        x_layer3=fold_result\n",
    "    else:\n",
    "        x_layer3=np.append(x_layer3,fold_result,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  train/validation split\n",
    "X_layer3_train, X_layer3_validation, y_layer3_train, y_layer3_validation = train_test_split( x_layer3,\n",
    "                                                                                y,\n",
    "                                                                                test_size=0.25,\n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188318\n",
      "188318\n",
      "XGB Mean abs error: 1140.71\n",
      "XGB predict time:1.51s\n"
     ]
    }
   ],
   "source": [
    "# The XGB layer3?\n",
    "print len(x_layer3)\n",
    "print len(y)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_layer3_train, label=y_layer3_train)\n",
    "dtest = xgb.DMatrix(X_layer3_validation)\n",
    "layer3_gbdt=xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "# now do a prediction and spit out a score(MAE) that means something\n",
    "start_time = time.time()\n",
    "layer3_gbdt_predict=layer3_gbdt.predict(dtest)\n",
    "MAE=np.mean(abs(layer3_gbdt_predict- y_layer3_validation))\n",
    "MAE=np.mean(abs(np.exp(layer3_gbdt_predict) - np.exp(y_layer3_validation)))\n",
    "MAE_tracking.append([\"run:{}\".format('XGBLayer3'),MAE])\n",
    "print(\"XGB Mean abs error: {:.2f}\".format(MAE))\n",
    "print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "#XGB Mean abs error: 1152.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['run:0-37663:0' 'run:0-37663:1' 'run:0-37663:2' 'run:0-37663:XGB'\n",
      "  'run:37663-75326:0' 'run:37663-75326:1' 'run:37663-75326:2'\n",
      "  'run:37663-75326:XGB' 'run:75326-112989:0' 'run:75326-112989:1'\n",
      "  'run:75326-112989:2' 'run:75326-112989:XGB' 'run:112989-150652:0'\n",
      "  'run:112989-150652:1' 'run:112989-150652:2' 'run:112989-150652:XGB'\n",
      "  'run:150652-188318:0' 'run:150652-188318:1' 'run:150652-188318:2'\n",
      "  'run:150652-188318:XGB' 'run:linearLayer2' 'run:KNNLayer2'\n",
      "  'run:XGBLayer2' 'run:linearLayer2' 'run:KNNLayer2' 'run:XGBLayer2'\n",
      "  'run:linearLayer2' 'run:KNNLayer2' 'run:XGBLayer2' 'run:linearLayer2'\n",
      "  'run:KNNLayer2' 'run:XGBLayer2' 'run:linearLayer2' 'run:KNNLayer2'\n",
      "  'run:XGBLayer2' 'run:XGBLayer3']\n",
      " ['1212.14825319' '1278.45853919' '1203.76338741' '1138.35538876'\n",
      "  '1210.12277464' '1273.57948617' '1204.21009999' '1133.69840899'\n",
      "  '1225.63498722' '1292.35723022' '1215.81104253' '1149.70203441'\n",
      "  '1222.33895835' '1296.75083708' '1212.2913242' '1142.2722771'\n",
      "  '1203.62440183' '1270.93079987' '1195.08823713' '1128.54106508'\n",
      "  '1136.546449' '1156.19983098' '1153.00422859' '1131.51592447'\n",
      "  '1152.97643182' '1149.09664616' '1148.07993256' '1166.88721004'\n",
      "  '1161.45995058' '1140.30526785' '1162.15156735' '1157.34009249'\n",
      "  '1126.0387128' '1148.55048933' '1141.9923442' '1140.71467314']]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGDCAYAAAAWKgYNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6ovaCqZVq1atWvVF/x9ssm/KYS/XQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c7c7fe290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "MAE_tracking_graph=np.array(MAE_tracking)\n",
    "\n",
    "print(MAE_tracking_graph.T)\n",
    "\n",
    "plt.plot(MAE_tracking_graph.T[1])\n",
    "plt.xlabel(MAE_tracking_graph.T[0])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del MAE_tracking_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict layer 1 on test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "predict time:122.11s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "predict time:5.323s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:11: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time:107.058s\n",
      "XGB predict time:320.577s\n",
      "AVG column added - length of new row: 6\n",
      "Fold run time:448.015s\n"
     ]
    }
   ],
   "source": [
    "x_layer2_test = []\n",
    "start_time1 = time.time()\n",
    "for i in range(len(regrList)): # for each of the regressions we use, fit/predict the data\n",
    "    start_time = time.time()            \n",
    "    estimator=skclone(regrList[i], safe=True)\n",
    "    print(estimator)\n",
    "    estimator.fit(x,y) # use the estimator from the training, but refit to the whole data set!\n",
    "    curr_predict=estimator.predict(x_test_data)\n",
    "    print(\"predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    \n",
    "    if x_layer2_test == []:\n",
    "        x_layer2_test = np.array(curr_predict.copy())\n",
    "    else:\n",
    "        x_layer2_test = np.column_stack((x_layer2_test,curr_predict))\n",
    "\n",
    "#XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
    "if use_xgb == True:\n",
    "\n",
    "    dtrain = xgb.DMatrix(x, label=y)\n",
    "    dtest = xgb.DMatrix(x_test_data)\n",
    "    gbdt=xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "    # now do a prediction and spit out a score(MAE) that means something\n",
    "    #start_time = time.time()\n",
    "    curr_predict=gbdt.predict(dtest)\n",
    "    x_layer2_test = np.column_stack((x_layer2_test,curr_predict))\n",
    "    #print(\"Mean abs error: {:.2f}\".format(np.mean(abs(cache[i+1] - y_test))))\n",
    "    print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "# add an avged column of all the runs\n",
    "avg_column=np.mean(x_layer2_test, axis=1)\n",
    "x_layer2_test=np.column_stack((x_layer2_test,avg_column))\n",
    "print(\"AVG column added - length of new row: {}\".format(len(x_layer2[0])))\n",
    "\n",
    "print(\"Fold run time:{}s\".format(round((time.time()-start_time1), 3) ))   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### This section is outdated, but still usefull in a historical sense.\n",
    "# some problems noted---fact finding below!\n",
    "display(\"size of original test data:\",len(x_test_data))\n",
    "display(\"Test shape:\",np.shape(x_layer2_test))\n",
    "display(\"train shape:\",np.shape(x_layer2))\n",
    "\n",
    "print(\"sample of layer2 test:\\n\",x_layer2_test[:4])\n",
    "\n",
    "print(\"x_layer2_test mean:\",x_layer2_test.mean( axis=0))\n",
    "print(\"x_layer2 mean:\",x_layer2.mean(axis=0))\n",
    "train_layer2_col0_mean=x_layer2.mean(axis=0)[0]\n",
    "\n",
    "print(\"x_layer2_test std:\",x_layer2_test.std( axis=0)) \n",
    "print(\"x_layer2 std:\",x_layer2.std(axis=0))\n",
    "\n",
    "# notice that column 0(linregresion) has a significantly higher mean and std\n",
    "# here's a hack to not fix that for now! \n",
    "\n",
    "# check which row in column 0 are significantly far from the mean\n",
    "problem_column=x_layer2_test.T[0]\n",
    "outliers=[]\n",
    "for i in range(len(problem_column)):\n",
    "    if problem_column[i]>30000:\n",
    "        outliers.append((i,problem_column[i]))\n",
    "print(\"num outliers:\",len(outliers))\n",
    "\n",
    "#for each problem child, set them to the average value from the train set, to null the affect some\n",
    "for o in outliers:\n",
    "    problem_column[o[0]]=train_layer2_col0_mean\n",
    "    \n",
    "print(problem_column[o[0]])\n",
    "\n",
    "#check outliers again\n",
    "problem_column=x_layer2_test.T[0]\n",
    "outliers=[]\n",
    "for i in range(len(problem_column)):\n",
    "    if problem_column[i]>30000:\n",
    "        outliers.append((i,problem_column[i]))\n",
    "print(\"num outliers:\",len(outliers))\n",
    "\n",
    "print(x_layer2_test.T[0][o[0]]) # verify that the change made it all the way to the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "redo kmeans with new cluster number from meanshift +1 to account for sampling...\n",
      "kmeans round 2 time:38.092s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Clusters sample:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([14, 30, 60, 27, 47, 22, 39, 43, 75,  5, 64, 43, 26, 67, 67], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'test-first 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.53882837,  7.36421311,  7.56065475,  7.46098852,  7.48117119],\n",
       "       [ 7.75194175,  7.60895517,  7.67783033,  7.67762709,  7.67908859],\n",
       "       [ 9.05288467,  9.43546791,  8.97044867,  9.06942368,  9.13205623]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of row: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test-first 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  7.53882837,   7.36421311,   7.56065475,   7.46098852,\n",
       "          7.48117119,  14.        ],\n",
       "       [  7.75194175,   7.60895517,   7.67783033,   7.67762709,\n",
       "          7.67908859,  30.        ],\n",
       "       [  9.05288467,   9.43546791,   8.97044867,   9.06942368,\n",
       "          9.13205623,  60.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of row: 6\n",
      "run time:38.105s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# use the new clusters number to predict each locations cluster\n",
    "print \"\\nredo kmeans with new cluster number from meanshift +1 to account for sampling...\"\n",
    "k_means =KMeans(n_clusters=80,n_jobs=12)\n",
    "final_clusters=k_means.fit_predict(x_layer2_test)\n",
    "print(\"kmeans round 2 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "display(\"Clusters sample:\",final_clusters[:15])\n",
    "\n",
    "display(\"test-first 3\",x_layer2_test[:3])\n",
    "print(\"length of row: {}\".format(len(x_layer2_test[0])))\n",
    "\n",
    "x_layer2_test=np.column_stack((x_layer2_test,final_clusters))\n",
    "\n",
    "display(\"test-first 3\",x_layer2_test[:3])\n",
    "print(\"length of row: {}\".format(len(x_layer2_test[0])))\n",
    "print(\"run time:{}s\".format(round((time.time()-start_time), 3) ))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2 predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear predict time:0.003s\n",
      "KNeighbors predict time:2.995s\n",
      "XGB predict time:4.941s\n",
      "AVG predict time:0.001s\n"
     ]
    }
   ],
   "source": [
    "#Linear\n",
    "start_time = time.time()\n",
    "layer3_predict_linear=layer2_Lin_regr.predict(x_layer2_test)\n",
    "print(\"Linear predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "x_layer3_test = layer3_predict_linear\n",
    "\n",
    "#KNeighborsRegressor\n",
    "start_time = time.time()\n",
    "layer3_predict_KNeighbors=layer2_KNN_regr.predict(x_layer2_test)\n",
    "print(\"KNeighbors predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "x_layer3_test = np.column_stack((x_layer3_test,layer3_predict_KNeighbors))  \n",
    "\n",
    "\n",
    "# The XGB version of layer 2\n",
    "dtest = xgb.DMatrix(x_layer2_test)\n",
    "start_time = time.time()\n",
    "layer3_gbdt_predict=layer2_gbdt.predict(dtest)\n",
    "print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "x_layer3_test = np.column_stack((x_layer3_test,layer3_gbdt_predict))  \n",
    "\n",
    "\n",
    "# ? average those weighted to XGB\n",
    "start_time = time.time()\n",
    "\n",
    "layer3_avg_predict=(layer3_predict_linear+layer3_predict_KNeighbors+layer3_gbdt_predict+layer3_gbdt_predict)/4\n",
    "print(\"AVG predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "\n",
    "x_layer3_test = np.column_stack((x_layer3_test,layer3_avg_predict))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,loss\\n',\n",
       " '4,1542.75355317\\n',\n",
       " '6,1995.66071952\\n',\n",
       " '9,8494.12829359\\n',\n",
       " '12,6138.85803957\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#spit out that good scoring linear result...\n",
    "test_data['loss']=np.exp(layer3_predict_linear)-200\n",
    "\n",
    "\n",
    "result=test_data[['id','loss',]]\n",
    "output_fname=\"result_submission_stack_linear.csv\"\n",
    "display(writeData(result,output_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,loss\\n',\n",
       " '4,1786.10314941\\n',\n",
       " '6,2006.43505859\\n',\n",
       " '9,9415.99023438\\n',\n",
       " '12,6253.11279297\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the XGB version:\n",
    "dtest = xgb.DMatrix(x_layer3_test)\n",
    "test_data['loss']=np.exp(layer3_gbdt.predict(dtest))-200\n",
    "\n",
    "result=test_data[['id','loss',]]\n",
    "output_fname=\"result_submission_stack_xgb.csv\"\n",
    "display(writeData(result,output_fname))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('result std:', id      170098.328125\n",
      "loss      1686.012573\n",
      "dtype: float32)\n"
     ]
    }
   ],
   "source": [
    "#let's have a look at the std of the result, as a cross check\n",
    "print(\"result std:\",result.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
