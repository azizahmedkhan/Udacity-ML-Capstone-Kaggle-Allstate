{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Just a nice stacking ensemble model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "test.csv.zip\n",
      "test_data_all_features.csv\n",
      "test_data_cats.csv\n",
      "test_data_conts.csv\n",
      "test_data_new.csv\n",
      "test_data_orig_only.csv\n",
      "train.csv\n",
      "train.csv.zip\n",
      "train_data_all_features.csv\n",
      "train_data_cats.csv\n",
      "train_data_conts.csv\n",
      "train_data_new.csv\n",
      "train_data_orig_only.csv\n",
      "\n",
      "clusters_cat.npy\n",
      "clusters_cat.npy_01.npy\n",
      "clusters_cat.npy_02.npy\n",
      "clusters_cont.npy\n",
      "clusters_cont.npy_01.npy\n",
      "clusters_cont.npy_02.npy\n",
      "clusters.npy\n",
      "clusters.npy_01.npy\n",
      "clusters.npy_02.npy\n",
      "grid_regr0-all_features.pkl\n",
      "grid_regr0-cats.pkl\n",
      "grid_regr0-conts.pkl\n",
      "grid_regr0-new.pkl\n",
      "grid_regr0-orig_only.pkl\n",
      "grid_regr1-all_features.pkl\n",
      "grid_regr1-cats.pkl\n",
      "grid_regr1-conts.pkl\n",
      "grid_regr1-new.pkl\n",
      "grid_regr1-orig_only.pkl\n",
      "grid_regr2-all_features.pkl\n",
      "grid_regr2-cats.pkl\n",
      "grid_regr2-conts.pkl\n",
      "grid_regr2-new.pkl\n",
      "grid_regr2-orig_only.pkl\n",
      "MAE_tracking-all_features.npy\n",
      "MAE_tracking-cats.npy\n",
      "MAE_tracking-conts.npy\n",
      "MAE_tracking-new.npy\n",
      "MAE_tracking.npy\n",
      "MAE_tracking-orig_only.npy\n",
      "oldmodels\n",
      "stat_tracking-Linear.npy\n",
      "x_layer2all_features.npy\n",
      "x_layer2all_features.npy_01.npy\n",
      "x_layer2cats.npy\n",
      "x_layer2cats.npy_01.npy\n",
      "x_layer2conts.npy\n",
      "x_layer2conts.npy_01.npy\n",
      "x_layer2new.npy\n",
      "x_layer2new.npy_01.npy\n",
      "x_layer2.npy\n",
      "x_layer2.npy_01.npy\n",
      "x_layer2orig_only.npy\n",
      "x_layer2orig_only.npy_01.npy\n",
      "x_layer2_test_all_features.npy\n",
      "x_layer2_test_all_features.npy_01.npy\n",
      "x_layer2_test_cats.npy\n",
      "x_layer2_test_cats.npy_01.npy\n",
      "x_layer2_test_conts.npy\n",
      "x_layer2_test_conts.npy_01.npy\n",
      "x_layer2_test_final.npy\n",
      "x_layer2_test_final.npy_01.npy\n",
      "x_layer2_test_new_.npy\n",
      "x_layer2_test_new.npy\n",
      "x_layer2_test_new_.npy_01.npy\n",
      "x_layer2_test_new.npy_01.npy\n",
      "x_layer2_test_orig_only.npy\n",
      "x_layer2_test_orig_only.npy_01.npy\n",
      "x_layer2_train_all_features.npy\n",
      "x_layer2_train_all_features.npy_01.npy\n",
      "x_layer2_train_cats.npy\n",
      "x_layer2_train_cats.npy_01.npy\n",
      "x_layer2_train_conts.npy\n",
      "x_layer2_train_conts.npy_01.npy\n",
      "x_layer2_train_final.npy\n",
      "x_layer2_train_final.npy_01.npy\n",
      "x_layer2_train_new.npy\n",
      "x_layer2_train-new.npy\n",
      "x_layer2_train_new.npy_01.npy\n",
      "x_layer2_train-new.npy_01.npy\n",
      "x_layer2_train_orig_only.npy\n",
      "x_layer2_train_orig_only.npy_01.npy\n",
      "x_layer2_w_clusters-new.npy_01.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os,sys,time,random,math,time\n",
    "import tarfile, zipfile\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor,RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import decomposition, datasets, ensemble\n",
    "from sklearn.cluster import KMeans,MeanShift\n",
    "\n",
    "from sklearn.base import clone as skclone\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import make_scorer,precision_score, recall_score, f1_score, average_precision_score, accuracy_score, mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import itertools\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Activation\n",
    "#from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "use_xgb=True #disable for speed\n",
    "\n",
    "from subprocess import check_output\n",
    "datadir=\"./input/\"\n",
    "cachedir=\"./cache/\"\n",
    "print(check_output([\"ls\", datadir]).decode(\"utf8\"))\n",
    "print(check_output([\"ls\", cachedir]).decode(\"utf8\"))\n",
    "\n",
    "\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(datadir,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    #data = pd.read_csv(filename)\n",
    "    data = ''\n",
    "    print (\"loading: \"+datadir+filename)\n",
    "    try:\n",
    "        if zipfile.is_zipfile(datadir+filename):\n",
    "            z = zipfile.ZipFile(datadir+filename)\n",
    "            filename = z.open(filename[:-4])\n",
    "        else:\n",
    "            filename=datadir+filename\n",
    "        data = pd.read_csv(filename, parse_dates=True)  \n",
    "        print (\"Dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be loaded. Is the dataset missing?\")\n",
    "        print(e)\n",
    "    return data\n",
    "\n",
    "def writeData(data,filename):\n",
    "    # Load the wholesale customers dataset\n",
    "    try:\n",
    "        data.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        print (\"Dataset could not be written.\")\n",
    "        print(e)\n",
    "    verify=[]\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                verify.append(line)\n",
    "        f.closed\n",
    "        return verify[:5]\n",
    "    except IOError:\n",
    "        sys.std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepdata(data_name,verbose=False):\n",
    "    ### and now, let's import the data\n",
    "    data = loadData(datadir,'train_data_'+data_name+'.csv')\n",
    "    if verbose==True:\n",
    "        display(data.info())\n",
    "        display(data.head(2))\n",
    "\n",
    "    test_data= loadData(datadir,'test_data_'+data_name+'.csv') \n",
    "    if verbose==True:\n",
    "        display(test_data.info())\n",
    "        display(test_data.head(2))\n",
    "    # we don't want the ID columns in X\n",
    "    x=data.drop(['id','loss'],1).values\n",
    "    # loss is our label\n",
    "    #y=data['loss'].values\n",
    "    y = np.log(data['loss']+shift).ravel()\n",
    "\n",
    "    return x,y,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def LabelEncoder(data):\n",
    "    # lifted in parts from:\n",
    "    #https://www.kaggle.com/mmueller/allstate-claims-severity/yet-another-xgb-starter/code\n",
    "    features = data.columns\n",
    "    cats = [feat for feat in features if 'cat' in feat]\n",
    "    for feat in cats:\n",
    "        data[feat] = pd.factorize(data[feat], sort=True)[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeansPlusmeanshift(data):\n",
    "    start_time = time.time()\n",
    "    startingClusterSize=int(len(data)*.075)\n",
    "    print \"kmeans.... for {} clusters\".format(startingClusterSize)\n",
    "    k_means =KMeans(n_clusters=startingClusterSize,n_jobs=10)\n",
    "    k_means.fit(data.sample(frac=0.35).values)\n",
    "    clusters=k_means.cluster_centers_\n",
    "    print(\"kmeans round 1 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    print clusters[:15]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #use the cluster centers of the guessed clusters to get an estimate of actual numbers of clusters. doing this for speed increase!\n",
    "    print \"\\nmeanshift...\"\n",
    "    meanshift=MeanShift(n_jobs=10)\n",
    "    meanshift.fit(clusters)\n",
    "    newcenters=meanshift.cluster_centers_\n",
    "    print(\"meanshift time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    print newcenters[:15], \"\\nnum of clusters from meanshift:\",len(newcenters)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # use the new clusters number to predict each locations cluster\n",
    "    print \"\\nredo kmeans with new cluster number from meanshift +1 to account for sampling...\"\n",
    "    k_means =KMeans(n_clusters=len(newcenters)+1,n_jobs=10)\n",
    "    final_clusters=k_means.fit_predict(data.values)\n",
    "    print(\"kmeans round 2 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeansPlusmeanshift_quick(data):  # used the one above to get the # of clusters, using this for speed\n",
    "    start_time = time.time()\n",
    "    # use the new clusters number to predict each locations cluster\n",
    "    print \"\\nredo kmeans with new cluster number from meanshift +1 to account for sampling...\"\n",
    "    k_means =KMeans(n_clusters=80,n_jobs=12)\n",
    "    final_clusters=k_means.fit_predict(data.values)\n",
    "    print(\"kmeans round 2 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_wrapper(x,y,regr,param,regr_name='BLANK'):\n",
    "    start_time = time.time()\n",
    "    print(\"In:{}\".format(regr))\n",
    "    filename= 'grid_{}.pkl'.format(regr_name)\n",
    "    if os.path.isfile(cachedir+filename):\n",
    "        print filename,\" exists, importing \"\n",
    "        return joblib.load(cachedir+filename) \n",
    "    else:\n",
    "        print(\"{} not present, running a gridsearch\".format(filename))\n",
    "        #search the param_grid for best params based on the f1 score\n",
    "        grid_search = GridSearchCV(regr,\n",
    "                                   param_grid= param,\n",
    "                                   n_jobs= -1,\n",
    "                                   scoring=make_scorer(mean_absolute_error,greater_is_better=False)) \n",
    "        print(\"debug 1\")\n",
    "        grid_search.fit(x,y)\n",
    "        print \"debug2\"\n",
    "        #reach into the grid search and pull out the best parameters, and set those on the clf\n",
    "        params={}\n",
    "        for p in grid_search.best_params_:\n",
    "            params[p]=grid_search.best_params_[p]\n",
    "        regr.set_params(**params)\n",
    "        print(\"run time:{}s\".format(round((time.time()-start_time), 3) ))   \n",
    "        joblib.dump(regr,cachedir+filename) \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XGB!\n",
    "\n",
    "#my first tries:\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 6,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'mae',\n",
    "}\n",
    "#params from:\n",
    "#https://www.kaggle.com/mnabaee/allstate-claims-severity/labelencoding-and-xgb-cv/discussion\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.3085,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.5,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 10,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 4.2922,\n",
    "    'eval_metric': 'mae',\n",
    "    'eta':0.001,\n",
    "    'gamma': 0.5290,\n",
    "    'subsample':0.9930,\n",
    "    'max_delta_step':0,\n",
    "    'booster':'gbtree',\n",
    "    'nrounds': 1001\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pre Proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ./input/train_data_all_features.csv\n",
      "Dataset has 188318 samples with 135 features each.\n",
      "loading: ./input/test_data_all_features.csv\n",
      "Dataset has 125546 samples with 135 features each.\n"
     ]
    }
   ],
   "source": [
    "shift=200\n",
    "\n",
    "data_name='all_features'\n",
    "x,y,test_data=prepdata(data_name)\n",
    "x_test_data=test_data.drop(['loss','id'],1).values# didn't have the loss column before, make it go away! don't need ID!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick our sklearn regressors, and do some param optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      " Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)]\n",
      "[ {'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [3, 5, 7, 10, 25, 50, 200, 500]}\n",
      " {'alpha': [0.05, 0.5, 1, 2, 4, 40, 140, 400]}\n",
      " {'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [2, 5, 7, 10, 25, 50, 200, 500]}]\n",
      "('number of scikitlearn regressors to use:', 3)\n"
     ]
    }
   ],
   "source": [
    "regressor_w_grid=[] # a list of regressions to use\n",
    "#regrList.append([LinearRegression()])\n",
    "regressor_w_grid.append([ExtraTreesRegressor(n_jobs = -1),\n",
    "                         dict(n_estimators=[3,5,7,10,25,50,200,500],\n",
    "                         max_features=['auto','sqrt','log2'])])\n",
    "regressor_w_grid.append([Ridge(),\n",
    "                         dict(alpha=[.05,.5,1,2,4,40,140,400])])\n",
    "regressor_w_grid.append([RandomForestRegressor(#criterion = 'mae',\n",
    "                                      n_jobs =-1, \n",
    "                                      random_state=42),\n",
    "                        dict(n_estimators=[2,5,7,10,25,50,200,500],\n",
    "                             max_features=['auto','sqrt','log2'])])\n",
    "#regressor_w_grid.append([KNeighborsRegressor(n_jobs = -1),\n",
    "                       # dict(n_neighbors=[2,5,7,15],\n",
    "                             #leaf_size =[3,10,15,25,30,50,100])])\n",
    "#regrList.append([SVR(), dict()]) # oh my so slow! and bad initial scores\n",
    "\n",
    "\n",
    "\n",
    "regrList=np.array(regressor_w_grid).T[0]\n",
    "paramater_grid=np.array(regressor_w_grid).T[1]\n",
    "print regrList\n",
    "print paramater_grid\n",
    "\n",
    "print(\"number of scikitlearn regressors to use:\",len(regrList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample train data size:150654'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  train/validation split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split( x,\n",
    "                                                                y,\n",
    "                                                               test_size=0.20,\n",
    "                                                                random_state=42)\n",
    "display(\"sample train data size:{}\".format(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "grid_regr0.pkl  exists, importing \n",
      "In:Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "grid_regr1.pkl  exists, importing \n",
      "In:RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "grid_regr2.pkl  exists, importing \n",
      "Full GridSearch run time:0.003s\n"
     ]
    }
   ],
   "source": [
    "start_time0 = time.time()\n",
    "for i in range(len(regrList)):\n",
    "    regrList[i]=grid_search_wrapper(X_train,y_train,regrList[i],paramater_grid[i],regr_name=\"regr{}\".format(i))\n",
    "    \n",
    "print(\"Full GridSearch run time:{}s\".format(round((time.time()-start_time0), 3) ))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:7.22672+0.00177631\ttest-mae:7.22672+0.00536231\n",
      "[100]\ttrain-mae:2.64648+0.000645226\ttest-mae:2.64657+0.00398503\n",
      "[200]\ttrain-mae:0.981322+0.000437563\ttest-mae:0.982543+0.00375753\n",
      "[300]\ttrain-mae:0.481692+0.000621212\ttest-mae:0.491434+0.00279426\n",
      "[400]\ttrain-mae:0.380619+0.000707563\ttest-mae:0.399574+0.00192014\n",
      "[500]\ttrain-mae:0.357262+0.000700708\ttest-mae:0.382938+0.00164532\n",
      "[600]\ttrain-mae:0.347403+0.000588488\ttest-mae:0.378616+0.00164711\n",
      "[700]\ttrain-mae:0.340663+0.000678476\ttest-mae:0.376688+0.00166054\n",
      "[800]\ttrain-mae:0.335234+0.000764873\ttest-mae:0.375584+0.00167685\n",
      "[900]\ttrain-mae:0.330477+0.000768185\ttest-mae:0.374767+0.00169156\n",
      "[1000]\ttrain-mae:0.326514+0.000812336\ttest-mae:0.374215+0.00172061\n",
      "[1100]\ttrain-mae:0.322813+0.000753445\ttest-mae:0.373784+0.00169393\n",
      "[1200]\ttrain-mae:0.319576+0.000650692\ttest-mae:0.373445+0.00171658\n",
      "[1300]\ttrain-mae:0.316523+0.00038135\ttest-mae:0.373181+0.00173508\n",
      "[1400]\ttrain-mae:0.313847+0.000220668\ttest-mae:0.372989+0.00175072\n",
      "[1500]\ttrain-mae:0.311318+0.000199525\ttest-mae:0.372823+0.00177604\n",
      "[1600]\ttrain-mae:0.308868+0.000166682\ttest-mae:0.372682+0.00176994\n",
      "[1700]\ttrain-mae:0.306419+0.000184337\ttest-mae:0.372563+0.00177345\n",
      "[1800]\ttrain-mae:0.304254+0.000147647\ttest-mae:0.372489+0.00175401\n",
      "[1900]\ttrain-mae:0.302198+0.000212445\ttest-mae:0.372431+0.00174293\n",
      "[2000]\ttrain-mae:0.300258+0.0002254\ttest-mae:0.372382+0.00172094\n",
      "CV time:790.786s\n",
      "CV-Mean: 0.37238175+0.00172093933289\n"
     ]
    }
   ],
   "source": [
    "#XGB\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "start_time = time.time()\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=2001, nfold=4, seed=42, stratified=False,\n",
    "             early_stopping_rounds=50, verbose_eval=100, show_stdv=True, maximize=False)\n",
    "print(\"CV time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "print('CV-Mean: {0}+{1}'.format(cv_mean, cv_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X_train, X_validation, y_train, y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Layer 1, train and predict for layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into k-folds(divisions). train the regressors on each combination of k-1 folds, and then predict on the held-out fold. Preserve the prediction of each regressor for the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train data: 188318\n",
      "folds at: [(0, 37663), (37663, 75326), (75326, 112989), (112989, 150652), (150652, 188318)]\n",
      "fold size: 37663\n",
      "train size: 150652\n",
      "188318\n"
     ]
    }
   ],
   "source": [
    "#prepare the fold divisions\n",
    "\n",
    "data_size=x.shape[0]\n",
    "print \"size of train data:\",data_size\n",
    "folds=[]\n",
    "num_folds=5\n",
    "fold_start=0\n",
    "for k in range(num_folds-1):\n",
    "    fold_end=((data_size/num_folds)*(k+1))\n",
    "    folds.append((fold_start,fold_end))\n",
    "    fold_start=fold_end\n",
    "folds.append((fold_start,data_size))\n",
    "print \"folds at:\",folds\n",
    "print \"fold size:\", (data_size/num_folds)\n",
    "print \"train size:\",(data_size/num_folds)*(num_folds-1)\n",
    "\n",
    "count=0\n",
    "for i in folds:\n",
    "    count+=i[1]-i[0]\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Fold:0 to 37663 of: 188318\n",
      "\n",
      "---folding! len test 37663, len train 150655\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "fit time:77.694s\n",
      "Mean abs error: 1212.15\n",
      "-predict time:4.394s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:4.209s\n",
      "Mean abs error: 1278.46\n",
      "-predict time:0.016s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:30: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit time:69.406s\n",
      "Mean abs error: 1203.76\n",
      "-predict time:3.772s\n",
      "XGB Mean abs error: 1138.36\n",
      "-XGB predict time:2.417s\n",
      "--layer2 length: 37663\n",
      "--layer2 shape: (37663, 4)\n",
      "---Fold run time:416.151s\n",
      "---Fold:37663 to 75326 of: 188318\n",
      "\n",
      "---folding! len test 37663, len train 150655\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "fit time:79.219s\n",
      "Mean abs error: 1210.12\n",
      "-predict time:4.156s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:4.031s\n",
      "Mean abs error: 1273.58\n",
      "-predict time:0.013s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "fit time:70.128s\n",
      "Mean abs error: 1204.21\n",
      "-predict time:3.877s\n",
      "XGB Mean abs error: 1133.70\n",
      "-XGB predict time:2.444s\n",
      "--layer2 length: 75326\n",
      "--layer2 shape: (75326, 4)\n",
      "---Fold run time:417.945s\n",
      "---Fold:75326 to 112989 of: 188318\n",
      "\n",
      "---folding! len test 37663, len train 150655\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:58: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fit time:80.256s\n",
      "Mean abs error: 1225.63\n",
      "-predict time:4.501s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:4.124s\n",
      "Mean abs error: 1292.36\n",
      "-predict time:0.014s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "fit time:71.116s\n",
      "Mean abs error: 1215.81\n",
      "-predict time:3.787s\n",
      "XGB Mean abs error: 1149.70\n",
      "-XGB predict time:2.53s\n",
      "--layer2 length: 112989\n",
      "--layer2 shape: (112989, 4)\n",
      "---Fold run time:421.219s\n",
      "---Fold:112989 to 150652 of: 188318\n",
      "\n",
      "---folding! len test 37663, len train 150655\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "fit time:80.495s\n",
      "Mean abs error: 1222.34\n",
      "-predict time:4.285s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:3.932s\n",
      "Mean abs error: 1296.75\n",
      "-predict time:0.013s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "fit time:72.175s\n",
      "Mean abs error: 1212.29\n",
      "-predict time:4.078s\n",
      "XGB Mean abs error: 1142.27\n",
      "-XGB predict time:2.584s\n",
      "--layer2 length: 150652\n",
      "--layer2 shape: (150652, 4)\n",
      "---Fold run time:424.711s\n",
      "---Fold:150652 to 188318 of: 188318\n",
      "\n",
      "---folding! len test 37666, len train 150652\n",
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "fit time:81.212s\n",
      "Mean abs error: 1203.62\n",
      "-predict time:4.353s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "fit time:4.005s\n",
      "Mean abs error: 1270.93\n",
      "-predict time:0.016s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "fit time:71.598s\n",
      "Mean abs error: 1195.09\n",
      "-predict time:3.766s\n",
      "XGB Mean abs error: 1128.54\n",
      "-XGB predict time:2.589s\n",
      "--layer2 length: 188318\n",
      "--layer2 shape: (188318, 4)\n",
      "---Fold run time:423.739s\n",
      "----Full run time:2103.767s\n"
     ]
    }
   ],
   "source": [
    "x_layer2=[]\n",
    "start_time0 = time.time()\n",
    "MAE_tracking=[]\n",
    "\n",
    "if os.path.isfile(cachedir+'x_layer2.npy'):\n",
    "    print 'x_layer2.npy',\" exists, importing \"\n",
    "    #reuse the run\n",
    "    x_layer2=joblib.load(cachedir+'x_layer2.npy') \n",
    "    MAE_tracking=joblib.load(cachedir+'MAE_tracking.npy')\n",
    "else:\n",
    "    for fold_start,fold_end in folds:\n",
    "        print(\"---Fold:{} to {} of: {}\".format(fold_start,fold_end,data_size))\n",
    "        start_time1 = time.time()\n",
    "        fold_result=[]\n",
    "\n",
    "        X_test = x[fold_start:fold_end].copy()\n",
    "        y_test = y[fold_start:fold_end].copy()\n",
    "        X_train=np.concatenate((x[:fold_start], x[fold_end:]), axis=0)\n",
    "        y_train=np.concatenate((y[:fold_start], y[fold_end:]), axis=0)\n",
    "        print \"\\n---folding! len test {}, len train {}\".format(len(X_test),len(X_train))\n",
    "\n",
    "        for i in range(len(regrList)): # for each of the regressions we use, fit/predict the data\n",
    "            print(regrList[i])\n",
    "            start_time = time.time()\n",
    "            estimator=skclone(regrList[i], safe=True)\n",
    "            estimator.fit(X_train,y_train)\n",
    "            print(\"\\nfit time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "            start_time = time.time()\n",
    "            curr_predict=np.array(estimator.predict(X_test)).copy()\n",
    "            if fold_result == []:\n",
    "                fold_result = curr_predict\n",
    "            else:\n",
    "                fold_result = np.column_stack((fold_result,curr_predict))  \n",
    "            #show some stats on that last regressions run\n",
    "            #MAE=np.mean(abs(curr_predict - y_test))\n",
    "            MAE=np.mean(abs(np.exp(curr_predict) - np.exp(y_test)))\n",
    "            MAE_tracking.append([\"run:{}-{}:{}\".format(fold_start,fold_end,i),MAE])\n",
    "            print(\"Mean abs error: {:.2f}\".format(MAE))\n",
    "            print(\"-predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "            #print(\"Score: {:.2f}\".format(estimator.score(X_test, y_test))) #delays the run...\n",
    "\n",
    "        #XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
    "        if use_xgb == True:\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "            dtest = xgb.DMatrix(X_test)\n",
    "            #gbdt=xgbfit(X_train,y_train)\n",
    "            gbdt=xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "            # now do a prediction and spit out a score(MAE) that means something\n",
    "            start_time = time.time()\n",
    "            curr_predict=gbdt.predict(dtest)\n",
    "            fold_result = np.column_stack((fold_result,curr_predict))   \n",
    "            #MAE=np.mean(abs(curr_predict - y_test))\n",
    "            MAE=np.mean(abs(np.exp(curr_predict) - np.exp(y_test)))\n",
    "            MAE_tracking.append([\"run:{}-{}:{}\".format(fold_start,fold_end,'XGB'),MAE])\n",
    "            print(\"XGB Mean abs error: {:.2f}\".format(MAE))\n",
    "            print(\"-XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "        if x_layer2 == []:\n",
    "            x_layer2=fold_result\n",
    "        else:\n",
    "            x_layer2=np.append(x_layer2,fold_result,axis=0)\n",
    "\n",
    "        print \"--layer2 length:\",len(x_layer2)\n",
    "        print \"--layer2 shape:\",np.shape(x_layer2)\n",
    "        print(\"---Fold run time:{}s\".format(round((time.time()-start_time1), 3) ))   \n",
    "    print(\"----Full run time:{}s\".format(round((time.time()-start_time0), 3) ))   \n",
    "    #preserve the run\n",
    "    joblib.dump(x_layer2,cachedir+'x_layer2.npy') \n",
    "    joblib.dump(MAE_tracking,cachedir+'MAE_tracking.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgd Mean abs error: 1179.07\n",
      "length of new row: 5\n"
     ]
    }
   ],
   "source": [
    "# add an avged column of all the runs\n",
    "\n",
    "avg_column=np.mean(x_layer2, axis=1)\n",
    "\n",
    "#MAE=np.mean(abs(avg_column - y))\n",
    "MAE=np.mean(abs(np.exp(avg_column) - np.exp(y)))\n",
    "print(\"avgd Mean abs error: {:.2f}\".format(MAE))\n",
    "x_layer2=np.column_stack((x_layer2,avg_column))\n",
    "print(\"length of new row: {}\".format(len(x_layer2[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test-first 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.72564088,  7.33350105,  7.77098668,  7.69497013,  7.63127468],\n",
       "       [ 7.69969656,  7.65916132,  7.64628168,  7.56129837,  7.64160948],\n",
       "       [ 8.35786941,  8.50399124,  8.35953566,  8.39824104,  8.40490934]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of row: 5\n"
     ]
    }
   ],
   "source": [
    "display(\"test-first 3\",x_layer2[:3])\n",
    "print(\"length of row: {}\".format(len(x_layer2[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put each in a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "redo kmeans with new cluster number from meanshift to account for sampling...\n",
      "kmeans round 2 time:45.394s\n",
      "length of row: 5\n",
      "length of row: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./cache/x_layer2_w_clusters.npy', './cache/x_layer2_w_clusters.npy_01.npy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "# use the new clusters number to predict each locations cluster\n",
    "print \"\\nredo kmeans with new cluster number from meanshift to account for sampling...\"\n",
    "k_means =KMeans(n_clusters=80,n_jobs=12)\n",
    "final_clusters=k_means.fit_predict(x_layer2)\n",
    "print(\"kmeans round 2 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "print(\"length of row: {}\".format(len(x_layer2[0])))\n",
    "      \n",
    "x_layer2=np.column_stack((x_layer2,final_clusters))\n",
    "print(\"length of row: {}\".format(len(x_layer2[0])))\n",
    "joblib.dump(x_layer2,cachedir+'x_layer2_w_clusters.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x_layer2=joblib.load(cachedir+'x_layer2_w_clusters.npy') \n",
    "\n",
    "\n",
    "x_layer2=joblib.load(cachedir+'x_layer2_train_final.npy') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "grid_L2_Lin.pkl not present, running a gridsearch\n",
      "debug 1\n",
      "debug2\n",
      "run time:2.053s\n",
      "In:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "          weights='uniform')\n",
      "grid_L2_KNN.pkl not present, running a gridsearch\n",
      "debug 1\n",
      "debug2\n",
      "run time:212.733s\n",
      "Full GridSearch run time:214.789s\n"
     ]
    }
   ],
   "source": [
    "# grid search on layer 2\n",
    "\n",
    "        \n",
    "start_time0 = time.time()\n",
    "\n",
    "paramater_grid_Lin=dict(normalize = [True,False])\n",
    "layer2_Lin_regr=grid_search_wrapper(x_layer2,y,LinearRegression(),paramater_grid_Lin,regr_name='L2_Lin')   \n",
    "\n",
    "paramater_grid_KNN=dict(n_neighbors=[2,5,7,15,30],\n",
    "                    leaf_size =[3,10,15,25,30,50,100])\n",
    "layer2_KNN_regr=grid_search_wrapper(x_layer2,y,KNeighborsRegressor(n_jobs = -1),paramater_grid_KNN,regr_name='L2_KNN')   \n",
    "    \n",
    "print(\"Full GridSearch run time:{}s\".format(round((time.time()-start_time0), 3) ))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:7.22685+0.0019794\ttest-mae:7.22685+0.00597406\n",
      "[100]\ttrain-mae:2.64561+0.000726717\ttest-mae:2.64565+0.00415396\n",
      "[200]\ttrain-mae:0.97928+0.000332931\ttest-mae:0.980004+0.00335018\n",
      "[300]\ttrain-mae:0.470254+0.000197869\ttest-mae:0.477332+0.00194334\n",
      "[400]\ttrain-mae:0.372682+0.000128795\ttest-mae:0.385597+0.000543546\n",
      "[500]\ttrain-mae:0.355982+0.000216965\ttest-mae:0.37242+0.000124311\n",
      "[600]\ttrain-mae:0.351419+0.00026219\ttest-mae:0.370602+0.000203618\n",
      "[700]\ttrain-mae:0.349114+0.000312757\ttest-mae:0.370344+0.000243862\n",
      "[800]\ttrain-mae:0.347188+0.000308502\ttest-mae:0.370313+0.000252609\n",
      "CV time:327.85s\n",
      "CV-Mean: 0.3703105+0.000253264190126\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_layer2, label=y)\n",
    "\n",
    "start_time = time.time()\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=2001, nfold=4, seed=42, stratified=False,\n",
    "             early_stopping_rounds=50, verbose_eval=100, show_stdv=True, maximize=False)\n",
    "print(\"CV time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "print('CV-Mean: {0}+{1}'.format(cv_mean, cv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=3, metric='minkowski',\n",
       "          metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(layer2_Lin_regr)\n",
    "display(layer2_KNN_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0 to 37663 of: 188318\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "LinearRegression Mean abs error: 1134.80\n",
      "Score: 0.58\n",
      "KNeighborsRegressor Mean abs error: 1412.63\n",
      "Score: 0.37\n",
      "XGB Mean abs error: 1138.05\n",
      "XGB predict time:0.974s\n",
      "AVG Mean abs error: 1166.76\n",
      "Fold:37663 to 75326 of: 188318\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "LinearRegression Mean abs error: 1129.84\n",
      "Score: 0.58\n",
      "KNeighborsRegressor Mean abs error: 1409.86\n",
      "Score: 0.37\n",
      "XGB Mean abs error: 1133.67\n",
      "XGB predict time:1.133s\n",
      "AVG Mean abs error: 1165.01\n",
      "Fold:75326 to 112989 of: 188318\n",
      "\n",
      "folding! len test 37663, len train 150655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:69: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression Mean abs error: 1147.05\n",
      "Score: 0.57\n",
      "KNeighborsRegressor Mean abs error: 1418.92\n",
      "Score: 0.37\n",
      "XGB Mean abs error: 1147.70\n",
      "XGB predict time:1.035s\n",
      "AVG Mean abs error: 1180.04\n",
      "Fold:112989 to 150652 of: 188318\n",
      "\n",
      "folding! len test 37663, len train 150655\n",
      "LinearRegression Mean abs error: 1138.64\n",
      "Score: 0.57\n",
      "KNeighborsRegressor Mean abs error: 1419.58\n",
      "Score: 0.36\n",
      "XGB Mean abs error: 1141.21\n",
      "XGB predict time:0.989s\n",
      "AVG Mean abs error: 1172.77\n",
      "Fold:150652 to 188318 of: 188318\n",
      "\n",
      "folding! len test 37666, len train 150652\n",
      "LinearRegression Mean abs error: 1126.22\n",
      "Score: 0.58\n",
      "KNeighborsRegressor Mean abs error: 1410.58\n",
      "Score: 0.36\n",
      "XGB Mean abs error: 1130.12\n",
      "XGB predict time:1.269s\n",
      "AVG Mean abs error: 1161.94\n"
     ]
    }
   ],
   "source": [
    "x_layer3 = []\n",
    "MAE_tracking=[]\n",
    "\n",
    "\n",
    "for fold_start,fold_end in folds:\n",
    "    print(\"Fold:{} to {} of: {}\".format(fold_start,fold_end,data_size))\n",
    "    start_time1 = time.time()\n",
    "    fold_result=[]\n",
    "    \n",
    "    X_layer2_validation = x_layer2[fold_start:fold_end].copy()\n",
    "    y_layer2_validation = y[fold_start:fold_end].copy()\n",
    "    X_layer2_train=np.concatenate((x_layer2[:fold_start], x_layer2[fold_end:]), axis=0)\n",
    "    y_layer2_train=np.concatenate((y[:fold_start], y[fold_end:]), axis=0)\n",
    "    print \"\\nfolding! len test {}, len train {}\".format(len(X_layer2_validation),len(X_layer2_train))\n",
    "    \n",
    "\n",
    "    layer2_Lin_regr.fit(X_layer2_train,y_layer2_train)\n",
    "    layer2_predict_linear=layer2_Lin_regr.predict(X_layer2_validation)\n",
    "    #show some stats on that last regressions run    \n",
    "    #MAE=np.mean(abs(layer2_predict_linear - y_layer2_validation))\n",
    "    MAE=np.mean(abs(np.exp(layer2_predict_linear) - np.exp(y_layer2_validation)))\n",
    "    MAE_tracking.append([\"run:{}\".format('linearLayer2'),MAE])\n",
    "    print(\"LinearRegression Mean abs error: {:.2f}\".format(MAE))\n",
    "    print(\"Score: {:.2f}\".format(layer2_Lin_regr.score(X_layer2_validation, y_layer2_validation)))\n",
    "    fold_result = layer2_predict_linear\n",
    "    #with LinearReg: Mean abs error: 1172.67\n",
    "\n",
    "    #KNeighborsRegressor\n",
    "    layer2_KNN_regr.fit(X_layer2_train,y_layer2_train)\n",
    "    layer2_predict_KNeighbors=layer2_KNN_regr.predict(X_layer2_validation)\n",
    "    #show some stats on that last regressions run    \n",
    "    #MAE=np.mean(abs(layer2_predict_KNeighbors - y_layer2_validation))\n",
    "    MAE=np.mean(abs(np.exp(layer2_predict_KNeighbors) - np.exp(y_layer2_validation)))\n",
    "    MAE_tracking.append([\"run:{}\".format('KNNLayer2'),MAE])\n",
    "    print(\"KNeighborsRegressor Mean abs error: {:.2f}\".format(MAE))\n",
    "    print(\"Score: {:.2f}\".format(layer2_KNN_regr.score(X_layer2_validation, y_layer2_validation)))\n",
    "    fold_result = np.column_stack((fold_result,layer2_predict_KNeighbors))  \n",
    "\n",
    "    #Mean abs error: 1291.64\n",
    "\n",
    "    # The XGB version of layer 2\n",
    "    dtrain = xgb.DMatrix(X_layer2_train, label=y_layer2_train)\n",
    "    dtest = xgb.DMatrix(X_layer2_validation)\n",
    "    layer2_gbdt=xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "    \n",
    "    # now do a prediction and spit out a score(MAE) that means something\n",
    "    start_time = time.time()\n",
    "    layer2_gbdt_predict=layer2_gbdt.predict(dtest)\n",
    "    #MAE=np.mean(abs(layer2_gbdt_predict- y_layer2_validation))\n",
    "    MAE=np.mean(abs(np.exp(layer2_gbdt_predict) - np.exp(y_layer2_validation)))\n",
    "    MAE_tracking.append([\"run:{}\".format('XGBLayer2'),MAE])\n",
    "    print(\"XGB Mean abs error: {:.2f}\".format(MAE))\n",
    "    print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "    fold_result = np.column_stack((fold_result,layer2_gbdt_predict))  \n",
    "    \n",
    "    #XGB Mean abs error: 1154.25\n",
    "    \n",
    "    # ? average those weighted to XGB\n",
    "    layer2_avg_predict=(layer2_predict_linear+layer2_predict_KNeighbors+layer2_gbdt_predict+layer2_gbdt_predict)/4\n",
    "\n",
    "    #MAE=np.mean(abs(layer2_avg_predict- y_layer2_validation))\n",
    "    MAE=np.mean(abs(np.exp(layer2_avg_predict) - np.exp(y_layer2_validation)))\n",
    "\n",
    "    print(\"AVG Mean abs error: {:.2f}\".format(MAE))\n",
    "    fold_result = np.column_stack((fold_result,layer2_avg_predict))  \n",
    "\n",
    "    #AVG Mean abs error: 1163.71\n",
    "    \n",
    "    if x_layer3 == []:\n",
    "        x_layer3=fold_result\n",
    "    else:\n",
    "        x_layer3=np.append(x_layer3,fold_result,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  train/validation split\n",
    "X_layer3_train, X_layer3_validation, y_layer3_train, y_layer3_validation = train_test_split( x_layer3,\n",
    "                                                                                y,\n",
    "                                                                                test_size=0.25,\n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188318\n",
      "188318\n",
      "XGB Mean abs error: 1150.22\n",
      "XGB predict time:1.138s\n"
     ]
    }
   ],
   "source": [
    "# The XGB layer3?\n",
    "print len(x_layer3)\n",
    "print len(y)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_layer3_train, label=y_layer3_train)\n",
    "dtest = xgb.DMatrix(X_layer3_validation)\n",
    "layer3_gbdt=xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "# now do a prediction and spit out a score(MAE) that means something\n",
    "start_time = time.time()\n",
    "layer3_gbdt_predict=layer3_gbdt.predict(dtest)\n",
    "MAE=np.mean(abs(layer3_gbdt_predict- y_layer3_validation))\n",
    "MAE=np.mean(abs(np.exp(layer3_gbdt_predict) - np.exp(y_layer3_validation)))\n",
    "MAE_tracking.append([\"run:{}\".format('XGBLayer3'),MAE])\n",
    "print(\"XGB Mean abs error: {:.2f}\".format(MAE))\n",
    "print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "#XGB Mean abs error: 1152.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['run:linearLayer2' 'run:KNNLayer2' 'run:XGBLayer2' 'run:linearLayer2'\n",
      "  'run:KNNLayer2' 'run:XGBLayer2' 'run:linearLayer2' 'run:KNNLayer2'\n",
      "  'run:XGBLayer2' 'run:linearLayer2' 'run:KNNLayer2' 'run:XGBLayer2'\n",
      "  'run:linearLayer2' 'run:KNNLayer2' 'run:XGBLayer2' 'run:XGBLayer3']\n",
      " ['1134.80464498' '1412.63286668' '1138.05485014' '1129.83559048'\n",
      "  '1409.86258525' '1133.66866178' '1147.05173924' '1418.92336116'\n",
      "  '1147.70384148' '1138.63994109' '1419.57821728' '1141.21413987'\n",
      "  '1126.22451637' '1410.57858585' '1130.12393575' '1150.21926978']]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEyCAYAAAAcB2z/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBKJREpMFAKRSCRSYv4/gY6uHn5bJYcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2fd26a8b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "MAE_tracking_graph=np.array(MAE_tracking)\n",
    "\n",
    "print(MAE_tracking_graph.T)\n",
    "\n",
    "plt.plot(MAE_tracking_graph.T[1])\n",
    "plt.xlabel(MAE_tracking_graph.T[0])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del MAE_tracking_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict layer 1 on test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=500, n_jobs=-1, oob_score=False, random_state=None,\n",
      "          verbose=0, warm_start=False)\n",
      "predict time:122.11s\n",
      "Ridge(alpha=40, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "predict time:5.323s\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:11: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time:107.058s\n",
      "XGB predict time:320.577s\n",
      "AVG column added - length of new row: 6\n",
      "Fold run time:448.015s\n"
     ]
    }
   ],
   "source": [
    "x_layer2_test = []\n",
    "start_time1 = time.time()\n",
    "for i in range(len(regrList)): # for each of the regressions we use, fit/predict the data\n",
    "    start_time = time.time()            \n",
    "    estimator=skclone(regrList[i], safe=True)\n",
    "    print(estimator)\n",
    "    estimator.fit(x,y) # use the estimator from the training, but refit to the whole data set!\n",
    "    curr_predict=estimator.predict(x_test_data)\n",
    "    print(\"predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "    \n",
    "    if x_layer2_test == []:\n",
    "        x_layer2_test = np.array(curr_predict.copy())\n",
    "    else:\n",
    "        x_layer2_test = np.column_stack((x_layer2_test,curr_predict))\n",
    "\n",
    "#XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
    "if use_xgb == True:\n",
    "\n",
    "    dtrain = xgb.DMatrix(x, label=y)\n",
    "    dtest = xgb.DMatrix(x_test_data)\n",
    "    gbdt=xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "    # now do a prediction and spit out a score(MAE) that means something\n",
    "    #start_time = time.time()\n",
    "    curr_predict=gbdt.predict(dtest)\n",
    "    x_layer2_test = np.column_stack((x_layer2_test,curr_predict))\n",
    "    #print(\"Mean abs error: {:.2f}\".format(np.mean(abs(cache[i+1] - y_test))))\n",
    "    print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "\n",
    "# add an avged column of all the runs\n",
    "avg_column=np.mean(x_layer2_test, axis=1)\n",
    "x_layer2_test=np.column_stack((x_layer2_test,avg_column))\n",
    "print(\"AVG column added - length of new row: {}\".format(len(x_layer2[0])))\n",
    "\n",
    "print(\"Fold run time:{}s\".format(round((time.time()-start_time1), 3) ))   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### This section is outdated, but still usefull in a historical sense.\n",
    "# some problems noted---fact finding below!\n",
    "display(\"size of original test data:\",len(x_test_data))\n",
    "display(\"Test shape:\",np.shape(x_layer2_test))\n",
    "display(\"train shape:\",np.shape(x_layer2))\n",
    "\n",
    "print(\"sample of layer2 test:\\n\",x_layer2_test[:4])\n",
    "\n",
    "print(\"x_layer2_test mean:\",x_layer2_test.mean( axis=0))\n",
    "print(\"x_layer2 mean:\",x_layer2.mean(axis=0))\n",
    "train_layer2_col0_mean=x_layer2.mean(axis=0)[0]\n",
    "\n",
    "print(\"x_layer2_test std:\",x_layer2_test.std( axis=0)) \n",
    "print(\"x_layer2 std:\",x_layer2.std(axis=0))\n",
    "\n",
    "# notice that column 0(linregresion) has a significantly higher mean and std\n",
    "# here's a hack to not fix that for now! \n",
    "\n",
    "# check which row in column 0 are significantly far from the mean\n",
    "problem_column=x_layer2_test.T[0]\n",
    "outliers=[]\n",
    "for i in range(len(problem_column)):\n",
    "    if problem_column[i]>30000:\n",
    "        outliers.append((i,problem_column[i]))\n",
    "print(\"num outliers:\",len(outliers))\n",
    "\n",
    "#for each problem child, set them to the average value from the train set, to null the affect some\n",
    "for o in outliers:\n",
    "    problem_column[o[0]]=train_layer2_col0_mean\n",
    "    \n",
    "print(problem_column[o[0]])\n",
    "\n",
    "#check outliers again\n",
    "problem_column=x_layer2_test.T[0]\n",
    "outliers=[]\n",
    "for i in range(len(problem_column)):\n",
    "    if problem_column[i]>30000:\n",
    "        outliers.append((i,problem_column[i]))\n",
    "print(\"num outliers:\",len(outliers))\n",
    "\n",
    "print(x_layer2_test.T[0][o[0]]) # verify that the change made it all the way to the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "redo kmeans with new cluster number from meanshift +1 to account for sampling...\n",
      "kmeans round 2 time:38.092s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Clusters sample:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([14, 30, 60, 27, 47, 22, 39, 43, 75,  5, 64, 43, 26, 67, 67], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'test-first 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.53882837,  7.36421311,  7.56065475,  7.46098852,  7.48117119],\n",
       "       [ 7.75194175,  7.60895517,  7.67783033,  7.67762709,  7.67908859],\n",
       "       [ 9.05288467,  9.43546791,  8.97044867,  9.06942368,  9.13205623]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of row: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test-first 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  7.53882837,   7.36421311,   7.56065475,   7.46098852,\n",
       "          7.48117119,  14.        ],\n",
       "       [  7.75194175,   7.60895517,   7.67783033,   7.67762709,\n",
       "          7.67908859,  30.        ],\n",
       "       [  9.05288467,   9.43546791,   8.97044867,   9.06942368,\n",
       "          9.13205623,  60.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of row: 6\n",
      "run time:38.105s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# use the new clusters number to predict each locations cluster\n",
    "print \"\\nredo kmeans with new cluster number from meanshift +1 to account for sampling...\"\n",
    "k_means =KMeans(n_clusters=80,n_jobs=12)\n",
    "final_clusters=k_means.fit_predict(x_layer2_test)\n",
    "print(\"kmeans round 2 time:{}s\".format(round((time.time()-start_time), 3) ))\n",
    "display(\"Clusters sample:\",final_clusters[:15])\n",
    "\n",
    "display(\"test-first 3\",x_layer2_test[:3])\n",
    "print(\"length of row: {}\".format(len(x_layer2_test[0])))\n",
    "\n",
    "x_layer2_test=np.column_stack((x_layer2_test,final_clusters))\n",
    "\n",
    "display(\"test-first 3\",x_layer2_test[:3])\n",
    "print(\"length of row: {}\".format(len(x_layer2_test[0])))\n",
    "print(\"run time:{}s\".format(round((time.time()-start_time), 3) ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_layer2_test=joblib.load(cachedir+'x_layer2_test_final.npy' ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2 predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (125546,25) and (30,) not aligned: 25 (dim 1) != 30 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-4d042f1bf73a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Linear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlayer3_predict_linear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer2_Lin_regr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_layer2_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Linear predict time:{}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_layer3_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer3_predict_linear\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0m_center_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 185\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (125546,25) and (30,) not aligned: 25 (dim 1) != 30 (dim 0)"
     ]
    }
   ],
   "source": [
    "#Linear\n",
    "start_time = time.time()\n",
    "layer3_predict_linear=layer2_Lin_regr.predict(x_layer2_test)\n",
    "print(\"Linear predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "x_layer3_test = layer3_predict_linear\n",
    "\n",
    "#KNeighborsRegressor\n",
    "start_time = time.time()\n",
    "layer3_predict_KNeighbors=layer2_KNN_regr.predict(x_layer2_test)\n",
    "print(\"KNeighbors predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "x_layer3_test = np.column_stack((x_layer3_test,layer3_predict_KNeighbors))  \n",
    "\n",
    "\n",
    "# The XGB version of layer 2\n",
    "dtest = xgb.DMatrix(x_layer2_test)\n",
    "start_time = time.time()\n",
    "layer3_gbdt_predict=layer2_gbdt.predict(dtest)\n",
    "print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "x_layer3_test = np.column_stack((x_layer3_test,layer3_gbdt_predict))  \n",
    "\n",
    "\n",
    "# ? average those weighted to XGB\n",
    "start_time = time.time()\n",
    "\n",
    "layer3_avg_predict=(layer3_predict_linear+layer3_predict_KNeighbors+layer3_gbdt_predict+layer3_gbdt_predict)/4\n",
    "print(\"AVG predict time:{}s\".format(round((time.time()-start_time), 3) ))    \n",
    "\n",
    "x_layer3_test = np.column_stack((x_layer3_test,layer3_avg_predict))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,loss\\n',\n",
       " '4,1542.75355317\\n',\n",
       " '6,1995.66071952\\n',\n",
       " '9,8494.12829359\\n',\n",
       " '12,6138.85803957\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#spit out that good scoring linear result...\n",
    "test_data['loss']=np.exp(layer3_predict_linear)-200\n",
    "\n",
    "\n",
    "result=test_data[['id','loss',]]\n",
    "output_fname=\"result_submission_stack_linear.csv\"\n",
    "display(writeData(result,output_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,loss\\n',\n",
       " '4,1786.10314941\\n',\n",
       " '6,2006.43505859\\n',\n",
       " '9,9415.99023438\\n',\n",
       " '12,6253.11279297\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the XGB version:\n",
    "dtest = xgb.DMatrix(x_layer3_test)\n",
    "test_data['loss']=np.exp(layer3_gbdt.predict(dtest))-200\n",
    "\n",
    "result=test_data[['id','loss',]]\n",
    "output_fname=\"result_submission_stack_xgb.csv\"\n",
    "display(writeData(result,output_fname))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('result std:', id      170098.328125\n",
      "loss      1686.012573\n",
      "dtype: float32)\n"
     ]
    }
   ],
   "source": [
    "#let's have a look at the std of the result, as a cross check\n",
    "print(\"result std:\",result.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
